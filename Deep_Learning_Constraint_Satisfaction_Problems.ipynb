{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Deep Learning & Constraint Satisfaction Problems\n",
    "\n",
    "---\n",
    "\n",
    "_Authors: Dhavide Aruliah_ and _Jacob Koehler_\n",
    "\n",
    "### Assignment Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "- [Question 1: Implementing a Hard Threshold Activation Function](#q-threshold)\n",
    "- [Question 2: Implementing the Perceptron Classifier](#q-classifier)\n",
    "- [Question 3: Identifying Misclassified Points](#q-misclassified)\n",
    "- [Question 4: Building the actual Perceptron Iteration](#q-iteration)\n",
    "- [Question 5: Implementing SoftMax](#q-softmax)\n",
    "- [Question 6: Implementing ReLU](#q-relu)\n",
    "- [Question 7: Preprocessing the Digit Features](#q-features)\n",
    "- [Question 8: Preprocessing the Targets](#q-targets)\n",
    "- [Question 9: Using the `MLPClassifier`](#q-MLP)\n",
    "- [Question 10: Setting up the Keras Architecture](#q-architecture)\n",
    "- [Question 11: Fitting the Neural Network to Training Data](#q-fitting)\n",
    "- [Question 12: Assessing Neural Network Model Accuracy](#q-assessing)\n",
    "- [Question 13: Preprocessing the Housing Features](#q-housing-features)\n",
    "- [Question 14: Preparing the Neural Network for Regression](#q-housing-setup)\n",
    "- [Question 15: Evaluating the Neural Network for Regression](#q-housing-eval)\n",
    "- [Question 16: Verifying a Valid *N*-Queens Chessboard](#q-queens-valid)\n",
    "- [Question 17: Solving the *N*-Queens Problem by Backtracking](#q-queens-solving)\n",
    "- [Question 18: Determining a Flight Itinerary](#q-flights-small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "This assignment provides an opportunity to get used to *artificial neural networks* for supervised machine learning. We'll do this first by looking at the *perceptron* algorithm as an early example of a neural network. By building a simple program implementing the perceptron, you'll get a sense of the mathematical ideas underlying the training if neural networks. From there, you'll experiment with [Keras](https://keras.io/) as an example of a framework for building neural networks and solve a simple classification problem as well as a regression problem.\n",
    "\n",
    "You will also solve a few *Constraint Satisfaction Problems* by backtracking (including the famous $N$-Queens problem).\n",
    "\n",
    "The goals of the present assignment are:\n",
    "+ to get used to the core terminology used with neural networks: layers, units, activation functions, etc.\n",
    "+ to implement the simplest neural network algorithm (the perceptron) to build a conceptual foundation on which neural networks are built.\n",
    "+ to solve som simple problems using a neural networks framework.\n",
    "+ to develop simple recursive functions for backtracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Standard boilerplate for Python for data science\n",
    "%matplotlib inline\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## The Perceptron\n",
    "\n",
    "To begin, you will replicate one of the first models of an artificial Neural Network that came from [Frank Rosenblatt](https://en.wikipedia.org/wiki/Frank_Rosenblatt) in 1957. While working on research funded by the US Defense Department, Rosenblatt investigated a straightforward approach to developing a classification model. You will construct a basic implementation of the Perceptron from scratch before moving to the Keras library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Assignment-Contents)\n",
    "\n",
    "---\n",
    "<a id=\"q-threshold\"></a>\n",
    "## Question 1: Implementing a Hard Threshold Activation Function\n",
    "\n",
    "Implement the hard threshold activation function `sign` with function signature `sign(t)` as given below.\n",
    "+ Your function should follow the convention\n",
    "  $$\\mathrm{sign}(t) = \\begin{cases} +1, & t\\ge0 \\\\ -1, &t<0 \\end{cases}$$\n",
    "  for any real value $t\\in\\mathbb{R}$.\n",
    "+ Make sure your function `sign` is [*vectorized*](https://docs.scipy.org/doc/numpy/glossary.html#term-vectorization) (i.e., is a [*universal function*](https://docs.scipy.org/doc/numpy/reference/ufuncs.html) in the parlance of Numpy). That is, it should accept a Numpy array as input and return a Numpy array of identical dimensions with entries $+1$ or $-1$ as required (i.e., the $\\text{sign}$ function should be applied elementwise to the array).\n",
    "+ Notice that `np.sign` won't work here (because `np.sign(0)==0` and you want `sign(0)==+1` instead).\n",
    "+ The function `np.where` is likely useful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "Q-01",
     "locked": false,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### QUESTION 1\n",
    "### Complete the body of the function sign (with signature below) in agreement with\n",
    "###   the details specified above.\n",
    "def sign(t):\n",
    "    \"\"\"Returns +1 for t>=0, -1 otherwise\n",
    "    >>> sign(np.array([-4, 3.5, 1.2, -5.6, 0, -2.1]))\n",
    "    array([-1.,  1.,  1., -1.,  1., -1.])\n",
    "    \"\"\"\n",
    "    res = np.ones(len(t))\n",
    "    res[np.where(t<0)] = -1.\n",
    "    return res\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.  1.  1. -1.  1. -1.]\n"
     ]
    }
   ],
   "source": [
    "print(sign(np.array([-4, 3.5, 1.2, -5.6, 0, -2.1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q-01",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Assignment-Contents)\n",
    "\n",
    "---\n",
    "<a id=\"q-classifier\"></a>\n",
    "\n",
    "## Question 2: Implementing the Perceptron Classifier\n",
    "\n",
    "Implement the function $f_{\\mathrm{perceptron}}$ with the signature `f_perceptrion(X, w, b)`. Mathematically, it could be written as $f_{\\mathrm{perceptron}}(x) = \\mathrm{sign}(W x^T +b)$ where $x$ is a row vector (i.e., one-dimensional array) of length $d$, $W$ is a row vector of length $d$, and $b$ is a scalar.\n",
    "+ You will make the function more flexible by allowing for $N\\times d$ *feature matrices* $X$ as input. In that case, the function can be computed as $f_{\\mathrm{perceptron}}(x) = \\mathrm{sign}(W X^T + b)$ (in which case the output is a $1\\times N$ vector rather than a $1\\times 1$ scalar).\n",
    "+ Tip: If the conventions around row & column vectors are messy, consider using `np.squeeze` to reduce two-dimensional row or column vectors to one-dimensional vectors. Numpy is very permissive about computing matrix-vector products using one-dimensional arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### QUESTION 2\n",
    "### Complete the function f_perceptron as specified above.\n",
    "###\n",
    "def f_perceptron(X, W, b):\n",
    "    '''Returns sign(W X^T + b)\n",
    "    >>> X = np.array([[ 3,  5,  2, -5,  3],\n",
    "                      [ 6,  2,  1,  8, -9],\n",
    "                      [ 4, -6, -7,  6, -9]])\n",
    "    >>> W, b = np.array([4,5,-2,0.2,1]), 1.5\n",
    "    >>> f_perceptron(X, W, b)\n",
    "    \n",
    "    array([ 1.,  1., -1.])\n",
    "    '''\n",
    "    X = np.squeeze(X)\n",
    "    return sign((np.dot(W,X.T)+b))\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1. -1.]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[ 3,  5,  2, -5,  3],\n",
    "                      [ 6,  2,  1,  8, -9],\n",
    "                      [ 4, -6, -7,  6, -9]])\n",
    "W, b = np.array([4,5,-2,0.2,1]), 1.5\n",
    "print(f_perceptron(X, W, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q-02",
     "locked": true,
     "points": "8",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Assignment-Contents)\n",
    "\n",
    "---\n",
    "<a id=\"q-misclassified\"></a>\n",
    "\n",
    "## Question 3: Identifying Misclassified Points\n",
    "\n",
    "Your task now is to write a function `find_misclassified` that identifies points that are misclassified by `f_perceptron` from above.\n",
    "+ The function signature is `find_misclassified(X, y, W, b)` with:\n",
    "  + $N\\times d$ *feature matrix* `X`;\n",
    "  + *weight vector* `W` of length $d$;\n",
    "  + (scalar) *bias* `b`; and\n",
    "  + target vector `y` of length $N$ with entries $+1$ or $-1$.\n",
    "  The inputs `X`, `W`, and `b` are exactly as required for evaluating `f_perceptron`.\n",
    "+ The output computed by the function `find_misclassified` is a one-dimensional Numpy array or a list of integers corresponding to rows of the input `X` that are misclassified by $f_{\\mathrm{perceptron}}$. That is, `find_misclassified` returns the rows $k$ between $0$ and $N-1$ for which\n",
    "  $$f_{\\mathrm{perceptron}}(X_{k,:}, W, b) \\neq y_{k},$$\n",
    "  where $X_{k,:}$ refers to the $k$th row of the $N\\times d$ matrix $X$.\n",
    "+ The row indices output by `find_misclassified` should be sorted in increasing order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### QUESTION 3\n",
    "### Complete the function find_misclassified as specified above.\n",
    "###\n",
    "def find_misclassified(X, y, W, b):\n",
    "    '''Returns 1D array of index values for which f_perceptron misclassifies rows of X\n",
    "    >>> W, b = np.array([-5,  5,  4, -3, -1, -8]), 0.47686675\n",
    "    >>> X = np.array([[ -5, -11, -13, -16, -13,  -7],\n",
    "    >>>               [ -1,  -7, -16,  13, -11,  11],\n",
    "    >>>               [  8,   7,   6, -16, -17,   0],\n",
    "    >>>               [  4,   6,  17,  14, -10,  -9],\n",
    "    >>>               [  0,  -5, -11,  15,  13,   8],\n",
    "    >>>               [ -5,  -2,   3,  10,   8,   8],\n",
    "    >>>               [ 19, -18,   6, -14,  16, -13]])\n",
    "    >>> y = np.array([ 1, -1,  1, -1,  1, -1,  1])\n",
    "    >>> find_misclassified(X, y, W, b)\n",
    "    array([3, 4, 6])\n",
    "    '''\n",
    "    res = f_perceptron(X, W, b)\n",
    "    return np.where(res!=y)[0]\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 6]\n"
     ]
    }
   ],
   "source": [
    "W, b = np.array([-5,  5,  4, -3, -1, -8]), 0.47686675\n",
    "X = np.array([[ -5, -11, -13, -16, -13,  -7],[ -1,  -7, -16,  13, -11,  11],[  8,   7,   6, -16, -17,   0],\n",
    "[  4,   6,  17,  14, -10,  -9],\n",
    "[  0,  -5, -11,  15,  13,   8],\n",
    "[ -5,  -2,   3,  10,   8,   8],\n",
    "[ 19, -18,   6, -14,  16, -13]])\n",
    "y = np.array([ 1, -1,  1, -1,  1, -1,  1])\n",
    "print(find_misclassified(X, y, W, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q-03",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Given training data $X$ & $y$ for a binary classification problem, you are now ready to implement the perceptron algorithm to determine a classifier with parameters $W$ and $b$. The basic steps are:\n",
    "\n",
    "+ Fix a random seed for the iteration (optional, but useful for reproducibility)\n",
    "+ Initialize $W$ and $b$ with some random values;\n",
    "+ REPEAT:\n",
    "  + Compute the set $\\mathcal{M}$ of rows of $X$ misclassified by $f_{\\mathrm{perceptron}}(\\cdot , W, b)$\n",
    "  + Draw a row index $k$ from $\\mathcal{M}$ at random\n",
    "  + Use the $k$th row of $X$ and the $k$th entry of the label vector $y$ to update $W$ and $b$:\n",
    "    $$\\begin{aligned} W &\\leftarrow W + \\eta y_{k} X_{k,:} \\\\ b &\\leftarrow b + \\eta y_{k} \\end{aligned}$$\n",
    "    (above $\\eta$ is a user-specified *learning rate*).\n",
    "+ UNTIL convergence (i.e., until $\\mathcal{M}$ is empty or, optionally, if the number of iterations is too large).\n",
    "\n",
    "Your next task is to write a function that carries out this iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Assignment-Contents)\n",
    "\n",
    "---\n",
    "<a id=\"q-iteration\"></a>\n",
    "## Question 4: Building the actual Perceptron Iteration\n",
    "\n",
    "+ The function `perceptron_iteration` with the signature `perceptron_iteration(X, y, eta=1.0, ITMAX=1000, random_state=None)`.\n",
    "  + the positional inputs `X` and `y` are exactly as before from `find_misclassified`.\n",
    "  + the optional keyword argument `eta` is the *learning rate* (default value `1.0`).\n",
    "  + the optional keyword argument `ITMAX` is the maximum number of iterations (default value `1000`).\n",
    "  + the optional keyword argument `random_state` is for seeding random number generation (default value `None`).\n",
    "+ Convergence is achieved when the set $\\mathcal{M}$ of row indices of misclassified points is *empty*.\n",
    "+ The function should return the weights $W$ and the bias term $b$ as a 2-tuple on convergence.\n",
    "+ If the iteration fails to converge within `ITMAX` iterations (i.e., if there are still points being misclassified), the function should return `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### QUESTION 4\n",
    "### Complete the function perceptron_iteration as laid out below.\n",
    "###\n",
    "def perceptron_iteration(X, y, eta=1.0, ITMAX=1000, random_state=None):\n",
    "    '''Applies the perceptron algorithm to compute weights W and bias b associated with a binary\n",
    "    classification problem defined by N by d feature matrix X and N-vector y of labels.\n",
    "    >>> W, b = np. array([-5,  5,  4, -3, -1, -8]), 0.47686675\n",
    "    >>> X = np.array([[ -5, -11, -13, -16, -13,  -7],\n",
    "    >>>               [ -1,  -7, -16,  13, -11,  11],\n",
    "    >>>               [  8,   7,   6, -16, -17,   0],\n",
    "    >>>               [  4,   6,  17,  14, -10,  -9],\n",
    "    >>>               [  0,  -5, -11,  15,  13,   8],\n",
    "    >>>               [ -5,  -2,   3,  10,   8,   8],\n",
    "    >>>               [ 19, -18,   6, -14,  16, -13]])\n",
    "    >>> y = np.array([ 1, -1,  1, -1,  1, -1,  1])\n",
    "    >>> W, b = perceptron_iteration(X, y)\n",
    "    >>> print(W)\n",
    "    >>> print(b)\n",
    "    Converged after 15 iterations\n",
    "    [ 32.96891939   4.96204112 -18.91160225 -33.74141678  32.16552454  -7.59447954]\n",
    "    [5.73103265]\n",
    "    '''\n",
    "    np.random.seed(seed=random_state) # DO NOT CHANGE THIS LINE\n",
    "    N, d = X.shape\n",
    "    W, b = np.random.randn(d), np.random.randn(1)\n",
    "    i = 0\n",
    "    while(i<ITMAX):\n",
    "        mue = find_misclassified(X, y, W, b)\n",
    "        if(mue.size == 0):\n",
    "            print(\"Converged at \",i+1,\"iterations\")\n",
    "            return W,b\n",
    "        idx = np.random.choice(mue)\n",
    "        W += eta*y[idx]*X[idx]\n",
    "        b+= eta*y[idx]\n",
    "        i+=1\n",
    "    return (None,None)\n",
    "   # Determine misclassified rows of X\n",
    "   # ITERATE:\n",
    "       # Choose an index k from misclassified rows\n",
    "       # Compute updates to W and b\n",
    "       # Determine misclassified rows of X with new W and b\n",
    "   # Return W & b (unless convergence failed, so return (None, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at  6 iterations\n",
      "[  2.93652811  -5.00363071 -12.62859554 -14.59209407   6.73070527\n",
      "  -2.19235233]\n",
      "[3.29438907]\n"
     ]
    }
   ],
   "source": [
    "W, b = np. array([-5,  5,  4, -3, -1, -8]), 0.47686675\n",
    "X = np.array([[ -5, -11, -13, -16, -13,  -7],\n",
    "[ -1,  -7, -16,  13, -11,  11],\n",
    "[  8,   7,   6, -16, -17,   0],\n",
    "[  4,   6,  17,  14, -10,  -9],\n",
    "[  0,  -5, -11,  15,  13,   8],\n",
    "[ -5,  -2,   3,  10,   8,   8],\n",
    "[ 19, -18,   6, -14,  16, -13]])\n",
    "y = np.array([ 1, -1,  1, -1,  1, -1,  1])\n",
    "W, b = perceptron_iteration(X, y)\n",
    "print(W)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q-04",
     "locked": true,
     "points": "20",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Assignment-Contents)\n",
    "\n",
    "---\n",
    "## Neural networks\n",
    "\n",
    "Recognizing that the perceptron has two conceptual layers (an *input* layer and an *output* layer) that connects spaces of disparate dimensions, we can extend this model to more general functions. That is, we can build a *multi-layer perceptron* with multiple input layers, each associated with their own weight matrix, bias vector, and activation function. It is possible to use more general *network architectures* with these components to represent more sophisticated functions. When multiple hidden layers are used, the network is often considered as a \"deep\" neural network, hence the term *deep learning*.\n",
    "\n",
    "A key component of this is the choice of *activation function*.\n",
    "\n",
    "+ For binary classification problems, the logistic activation function\n",
    "  $$ \\sigma(t) = \\frac{e^{t}}{1+e^t} $$\n",
    "  (as seen from logisitc regression) is useful for probabilities of belonging to one of the two classes.\n",
    "+ For multiclass classification problems, the $\\text{softmax}$ function is often used to provide probabilities of belonging to any of a number of classes. It is a mapping $x \\mapsto \\mathrm{softmax}(x)$ of a vector of length $d$ to another vector of length $d$ defined by\n",
    "  $$[\\mathrm{softmax}(x)]_{k} := \\frac{e^{x_k}}{\\sum_{i=1}^{d}e^{x_{i}}} = \\frac{\\exp(x_k)}{\\sum_{i=1}^{d} \\exp(x_i)} \\qquad(k=1,2,\\dotsc,d).$$\n",
    "  Notice that the nonnegative entries of $\\mathrm{softmax}(x)$ add up to $1$ so it is, in effect, a discrete probability mass function.\n",
    "+ The *ReLU* (\"rectified linear unit\") function is a piecewise linear function defined by\n",
    "  $$\\mathrm{relu}(t) = \\begin{cases} t, & t\\ge0 \\\\ 0, &t<0 \\end{cases}.$$\n",
    "  The ReLU function is often used in between internal layers of a regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Assignment-Contents)\n",
    "\n",
    "---\n",
    "<a id=\"q-softmax\"></a>\n",
    "## Question 5: Implementing `softmax`\n",
    "\n",
    "For this task, you will complete the Python function `softmax` function defined by\n",
    "$$[\\mathrm{softmax}(x)]_{k} := \\frac{e^{x_k}}{\\sum_{i=1}^{d}e^{x_{i}}} = \\frac{\\exp(x_k)}{\\sum_{i=1}^{d} \\exp(x_i)}.$$\n",
    "+ To obtain a more numerically robust implementation, do the following: if $M=\\max_{i}(x_{i})$, then\n",
    "  $$[\\mathrm{softmax}(x)]_{k} = \\frac{\\exp(x_k - M)}{\\sum_{i=1}^{d} \\exp(x_i-M)}.$$\n",
    "  You will complete the function `softmax` using this version (which does not overflow for large values of $x_k$).\n",
    "+ Make sure your function is *vectorized* (i.e., is a *universal function* in the parlance of Numpy). That is, it should accept a Numpy array as input and return a Numpy array of identical dimensions with appropriate real-valued entries required (i.e., the $\\mathrm{softmax}$ function should be applied elementwise to the array)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### QUESTION 5\n",
    "### Complete the function softmax as defined above.\n",
    "###\n",
    "def softmax(x):\n",
    "    '''Returns smoothed version of max. function\n",
    "    >>> x = np.array([3,-2,5,1,0])\n",
    "    >>> softmax(x)\n",
    "    array([1.16537670e-01, 7.85224641e-04, 8.61103378e-01, 1.57716585e-02, 5.80206892e-03])\n",
    "    '''\n",
    "    M = max(x)\n",
    "    return np.exp(x-M)/np.sum(np.exp(x-M))\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.16537670e-01 7.85224641e-04 8.61103378e-01 1.57716585e-02\n",
      " 5.80206892e-03]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([3,-2,5,1,0])\n",
    "print(softmax(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "Q-05",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Assignment-Contents)\n",
    "\n",
    "---\n",
    "<a id=\"q-relu\"></a>\n",
    "## Question 6: Implementing `relu`\n",
    "\n",
    "You task here is to complete the function `relu` (the *rectified linear unit* or \"ReLU\" function) with signature given below.\n",
    "+ Your function `relu` should follow the convention\n",
    "  $$\\mathrm{relu}(t) = \\begin{cases} t, & t\\ge0 \\\\ 0, &t<0 \\end{cases}$$\n",
    "  for any real value $t\\in\\mathbb{R}$.\n",
    "+ Make sure your function is *vectorized* (i.e., is a *universal function* in the parlance of Numpy). That is, it should accept a Numpy array as input and return a Numpy array of identical dimensions with appropriate real-valued entries required (i.e., the $\\mathrm{relu}$ function should be applied elementwise to the array).\n",
    "+ The function `np.where` is likely useful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### QUESTION 6\n",
    "### Complete the function relu as specified above.\n",
    "###\n",
    "def relu(t):\n",
    "    '''Returns t for t>=0, zero otherwise\n",
    "    >>> x = np.array([ 0.10496716,  0.39051915,  2.29579808, -0.22517898,  0.42348426,  0.59049302])\n",
    "    \n",
    "    array([0.10496716, 0.39051915, 2.29579808, 0.        , 0.42348426,       0.59049302])\n",
    "    '''\n",
    "    t[np.where(t<0)] = 0.\n",
    "    return t\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10496716 0.39051915 2.29579808 0.         0.42348426 0.59049302]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([ 0.10496716,  0.39051915,  2.29579808, -0.22517898,  0.42348426,  0.59049302])\n",
    "print(relu(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q-06",
     "locked": true,
     "points": "4",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Assignment-Contents)\n",
    "\n",
    "---\n",
    "## MNIST Digit Classification with Neural Networks\n",
    "\n",
    "In the next few exercises, you'll get a chance to solve the [MNIST handwritten digits classification problem](http://yann.lecun.com/exdb/mnist/) first using using Scikit-Learn, and then using [Keras](http://keras.io) (a framework for neural networks explicitly). The Keras package provides [utilities to work with numerous datasets](https://keras.io/datasets/), but we'll avoid those here (to limit needless network traffic). Instead, we've created a compressed Numpy file in the local `assets` folder that contains the relevant data. The next few lines extract the arrays `X_train`, `y_train`, `X_test`, and `y_test` from that file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/mnist.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-0630bd5a93a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/mnist.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_train_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_test_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_train_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_test_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/mnist.npz'"
     ]
    }
   ],
   "source": [
    "d_file = np.load('data/mnist.npz')\n",
    "X_train_orig = d_file['X_train']\n",
    "X_test_orig = d_file['X_test']\n",
    "y_train_orig = d_file['y_train'].reshape(-1,1)\n",
    "y_test_orig = d_file['y_test'].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_file = np.load('mnist.npz')\n",
    "X_train_orig = d_file['X_train']\n",
    "X_test_orig = d_file['X_test']\n",
    "y_train_orig = d_file['y_train'].reshape(-1,1)\n",
    "y_test_orig = d_file['y_test'].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) 47040000\n",
      "(10000, 28, 28) 7840000\n",
      "(60000, 1) 60000\n",
      "(10000, 1) 10000\n"
     ]
    }
   ],
   "source": [
    "for arr in [X_train_orig, X_test_orig, y_train_orig, y_test_orig]:\n",
    "    print(arr.shape, arr.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract a single image\n",
    "idx = 45621\n",
    "digit_image = X_train_orig[idx]\n",
    "plt.imshow(digit_image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Associated label: {}'.format(y_train_orig[idx]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Assignment-Contents)\n",
    "\n",
    "---\n",
    "<a id=\"q-features\"></a>\n",
    "## Question 7: Preprocessing the Digit Features\n",
    "\n",
    "As a first step, preprocess the features in the arrays `X_train_orig` & `X_test_orig`.\n",
    "\n",
    "+ Reshape the three-dimensional arrays into two-dimensional arrays.\n",
    " + Numpy arrays have a method for reshaping (or use the function `np.reshape`).\n",
    "+ Rescale the integer values to be real values between 0 and 1.\n",
    " + Divide the arrays by 255.0 (the grayscale images have integer values between 0 & 255 by default).\n",
    "+ Bind the rescaled & reshaped training & testing arrays to `X_train` & `X_test` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (1680000, 28)\n",
      "X_test:  (280000, 28)\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "### QUESTION 7\n",
    "### Rescale & reshape the feature arrays X_train_orig & X_test_orig as described above.\n",
    "### Assign the results to X_train & X_test respectively.\n",
    "### YOUR SOLUTION HERE:\n",
    "X_train = (X_train_orig.transpose(2,0,1).reshape(-1,X_train_orig.shape[1]))/255.0\n",
    "X_test  = (X_test_orig.transpose(2,0,1).reshape(-1,X_test_orig.shape[1]))/255.0\n",
    "### For verification:\n",
    "print('X_train: {}'.format(X_train.shape))\n",
    "print('X_test:  {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q-07",
     "locked": true,
     "points": "8",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Assignment-Contents)\n",
    "\n",
    "---\n",
    "<a id=\"q-targets\"></a>\n",
    "## Question 8: Preprocessing the Targets\n",
    "\n",
    "As a second step, preprocess the targets `y_train_orig` & `y_test_orig` by converting them to two-dimensional arrays with one-hot encoded rows (each corresponding to a particular categorical label).\n",
    "+ You can use [`sklearn.preprocessing.OneHotEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) to do the encoding. The result should should be a two-dimensional array of ones & zeros of shape `(60000,10)` for `y_train` and another of shape `(10000,100)` for `y_test`. Each row should be all zeros except for a single entry of one in the postion corresponding to the appropriate digit. For instance:\n",
    "  ```python\n",
    ">>> print(y_test_orig[:3])   #  labels *before* one-hot encoding\n",
    "[[7]\n",
    " [2]\n",
    " [1]]\n",
    ">>> print(y_test[:3])        # labels *after* one-hot-encoding\n",
    "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
    " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
    "  ```\n",
    "+ Bind the results to `y_train` and `y_test`.\n",
    "+ Alternatively, the function `to_categorical` from `keras.utils` can be used for this task (but it does not provide the option for sparse representation as with the Scikit-Learn `OneHotEncoder`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train: (60000, 10)\n",
      "y_test:  (10000, 10)\n",
      "[[7]\n",
      " [2]\n",
      " [1]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "### QUESTION 8\n",
    "### Convert the target arrays y_train_orig & y_test_orig as described above.\n",
    "### Assign the results to y_train & y_test respectively.\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "### YOUR SOLUTION HERE:\n",
    "enc = OneHotEncoder() \n",
    "y_train = enc.fit_transform(y_train_orig)\n",
    "y_test = enc.fit_transform(y_test_orig)\n",
    "### For verification:\n",
    "print('y_train: {}'.format(y_train.shape))\n",
    "print('y_test:  {}'.format(y_test.shape))\n",
    "print(y_test_orig[:3])\n",
    "print(y_test[:3].todense()) # First three rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q-08",
     "locked": true,
     "points": "7",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### ScikitLearn `MLPClassifier`\n",
    "\n",
    "Now the data is loaded and ready to be processed, we can feed it into a simple feed-forward neural network.\n",
    "ScikitLearn has a straightforward implementation of a *Multi-layered Perceptron* (see the documemtation for the [`MLPClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) class).  Here, we have control over aforementioned parameters like the activation function and the learning rate.\n",
    "\n",
    "[Back to top](#Assignment-Contents)\n",
    "\n",
    "---\n",
    "<a id=\"q-MLP\"></a>\n",
    "### Question 9: Using the `MLPClassifier`\n",
    "\n",
    "Your task here is to complete the code below to instantiate an `MLPClassifier`.\n",
    "+ Set `activation='logistic'` to choose a logistic activation function.\n",
    "+ Use `hidden_layer_sizes=(512,)` to create a single hidden layer with 512 units.\n",
    "+ Set the `max_iter` parameter to `5` to limit the number of iterations (or *epochs*) of gradient descent.\n",
    "+ Use `learning_rate='constant'` to keep the learning rate fixed and set `learning_rate_init` to `0.1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### QUESTION 9\n",
    "### The MLPClassifier works as our other sklearn estimator classes\n",
    "### Below you are to instantiate an MLPClassifier\n",
    "### with a sigmoid ('logistic') activation function and learning rate\n",
    "### of 0.01.\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "### YOUR SOLUTION HERE:\n",
    "mlp = MLPClassifier(activation='logistic',hidden_layer_sizes=(512,),max_iter = 5,learning_rate='constant',learning_rate_init = 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q-09",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Having instantiated the `MLPClassifier`, you can fit it to the training data and assess the accuracy in the usual way with Scikit-Learn estimator `fit` and `predict` (or `score`) methods. Notice, however, that this is rather slow (about 25 seconds on my laptop with 16GB RAM).\n",
    "\n",
    "**Note**: If you experience timeouts, you may want to leave the next cell commented out (and the one that follows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# LEAVE THIS CELL COMMENTED OUT THIS CELL IF YOU EXPERINCE TIMEOUTS!\n",
    "# mlp.fit(X_train, y_train)   # Fitting to the training data is not so fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# LEAVE THIS CELL COMMENTED OUT THIS CELL IF YOU EXPERINCE TIMEOUTS!\n",
    "# y_pred = mlp.predict(X_test)  # Prediction is much faster\n",
    "# # Prediction is must faster\n",
    "# accuracy_train = mlp.score(X_train, y_train)\n",
    "# accuracy_test = mlp.score(X_test, y_test)\n",
    "# print('Training accuracy: {:5.3f}'.format(accuracy_train))\n",
    "# print('Testing  accuracy: {:5.3f}'.format(accuracy_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Assignment-Contents)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Introduction to Keras\n",
    "\n",
    "<center>\n",
    "    <a href=\"http://keras.io\"><img src = \"assets/keras.png\" width = \"50%\" height = \"50%\" /></a>\n",
    "</center>\n",
    "\n",
    "Now that you have some familiarity the perceptron as a simple neural network and with the multi-layer perceptron in Scikit-Learn, you can use [Keras](http://keras.io) as a more practical framework to solve problems using neural networks. Keras is a library that provides a simple API for neural network algorithms on top of lower-level libraries like [Tensorflow](https://www.tensorflow.org/) or [Theano](https://github.com/Theano/Theano). Other high-level frameworks for neural networks (\"deep learning\") include [Chainer](https://chainer.org/) and [PyTorch](https://pytorch.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Assignment-Contents)\n",
    "\n",
    "---\n",
    "<a id=\"q-architecture\"></a>\n",
    "## Question 10: Setting up the Keras Architecture\n",
    "\n",
    "You are now ready to instantiate a neural network model to solve the digits classification problem. This is referred to as specifying the *architecture* of the neural network.\n",
    "\n",
    "+ To initialize the model, instantiate an object of the class `models.Sequential`. Use the default options.\n",
    "+ Add a hidden layer using `network.add` with `layers.Dense`.\n",
    "  + The first argument to `layers.Dense` is `512` (for 512 units).\n",
    "  + Use the keyword argument `activation='relu'` to specify the ReLU activation function for this layer.\n",
    "  + As this is the first layer instantiated, it is necessary to specify `input_shape` as a *tuple*.\n",
    "+ Add a final output layer using `network.add` & `layers.Dense`.\n",
    "  + This layer will have 10 units and `activation='softmax'` to specify the final output of the setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### QUESTION 10\n",
    "### Create the neural network architecture using models.Sequential.\n",
    "###   Bind the object to the identifier \"network\" and add two layers: a dense layer with\n",
    "###   512 units with an activation function 'relu' and another dense layer, this time with\n",
    "###  10 units and an activation function 'softmax'. Remember that the first layer requires\n",
    "###  specification of the input dimensions. \n",
    "from keras import models\n",
    "from keras import layers\n",
    "### YOUR SOLUTION HERE:\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(units=512, activation='relu', input_shape=(784,)))\n",
    "network.add(layers.Dense(units=10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q-10",
     "locked": true,
     "points": "12",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "To get `network` ready to fit to the training data, you have to first *compile* it. This involves specifying the optimizer (a choice of strategies to apply to solve for the network parameters), the loss function to minimize (categorical cross-entropy in this case as is common for multi-class classification problems), and a choice of metrics to track in the iterative process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Assignment-Contents)\n",
    "\n",
    "---\n",
    "<a id=\"q-fitting\"></a>\n",
    "## Question 11: Fitting the Neural Network to Training Data\n",
    "\n",
    "You can fit the training data to the neural network using the `fit` method.\n",
    "+ The `fit` method requires the feature array `X_train` and the target array `y_train` as inputs.\n",
    "+ As optional keyword arguments, specify `epochs=5` (the number of sweeps through the data to make) and `batch_size=128` (the number of data points to use in each sweep through the data). This is in principle the same as the iterations of stochastic gradient descent (with a batch size of 1) made in the perceptron algorithm.\n",
    "+ Bind the output of `network.fit` to the identifier `history`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### QUESTION 11\n",
    "### Apply the fit method to the object network to using the training data and the options\n",
    "###   specified above. Assign the result to the identifier history.\n",
    "### YOUR SOLUTION HERE:\n",
    "history = network.fit(X_train,y_train,epochs=5,batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q-11",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Assignment-Contents)\n",
    "\n",
    "---\n",
    "<a id=\"q-assessing\"></a>\n",
    "## Question 12: Assessing Neural Network Model Accuracy\n",
    "\n",
    "Finally, you can assess the accuracy of the classification model `network` using the testing data.\n",
    "+ Apply the `evaluate` method to the object `network` with the testing data `X_test` & `y_test` as input.\n",
    "+ The output will be a sequence of two values: the loss and the accuracy. Assign these values to `test_loss` and `test_acc` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### QUESTION 12\n",
    "### Use the testing arrays X_test & y_test to compute the loss function & accuracy on the test data.\n",
    "###   Assign the results to test_loss & test_acc respectively.\n",
    "### YOUR SOLUTION HERE:\n",
    "score = network.evaluate(X_test,y_test)\n",
    "print(score)\n",
    "test_loss = score[0]\n",
    "test_acc = score[1]\n",
    "print('test_loss: {:9.4g}'.format(test_loss))\n",
    "print('test_acc:  {:9.4g}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q-12",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Now you've worked through this, you've built your first neural network model from end-to-end in Keras!\n",
    "\n",
    "[Back to top](#Assignment-Contents)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Using Keras for Linear Regression: Boston Housing data\n",
    "\n",
    "Using Keras in a regression setting is very similar to doing so for classification examples.  We will work through a basic implementation using the Boston Housing dataset from Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "d_file = np.load('data/boston.npz')\n",
    "train_data = d_file['train_data']\n",
    "test_data = d_file['test_data']\n",
    "train_targets = d_file['train_targets']\n",
    "test_targets = d_file['test_targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_file = np.load('boston.npz')\n",
    "train_data = d_file['train_data']\n",
    "test_data = d_file['test_data']\n",
    "train_targets = d_file['train_targets']\n",
    "test_targets = d_file['test_targets']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "To begin, we need to standardize our data.   Recall that the standard score of a sample $x$ is calculated as:\n",
    "\n",
    "$$z = \\frac{(x - \\mu)}{  s}$$\n",
    "\n",
    "\n",
    "where $\\mu$ is the mean of the training samples or zero if and $s$ is the standard deviation of the training samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Assignment-Contents)\n",
    "\n",
    "---\n",
    "<a id=\"q-housing-features\"></a>\n",
    "\n",
    "## Question 13:Preprocessing the Housing Features\n",
    "\n",
    "Your task here is to *standardize* the features of the housing data using the transformation above.\n",
    "+ Given the two-dimensional array of features in `train_data`, replace each column by subtracting its mean and dividing by its standard deviation.\n",
    "+ Assign the results to `scaled_train` and `scaled_test`.\n",
    "+ Be sure to use the means & standard deviations from the *training* data to standardize the *testing* data. That is, the standardizing transformation can only rely on information known *a propri* from training; it cannot know statistical properties of future testing instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-43503c9a7867>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-43503c9a7867>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    mean =\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "### QUESTION 13\n",
    "### Assign scaled_train and scaled test as described above.\n",
    "### YOUR SOLUTION HERE:\n",
    "mean_train = np.mean(np.array(train_data),axis=1)\n",
    "std_train = np.std(np.array(train_data), axis = 1)\n",
    "mean_test = np.mean(np.array(test_data),axis=1)\n",
    "std_test = np.std(np.array(test_data), axis = 1)\n",
    "scaled_train = np.divide((np.subtract(np.array(train_data),mean_train)),std_train)\n",
    "scaled_test = np.divide((np.subtract(np.array(test_data),mean_test)),std_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q-13",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Assignment-Contents)\n",
    "\n",
    "---\n",
    "<a id=\"q-housing-setup\"></a>\n",
    "## Question 14: Preparing the Neural Network for Regression\n",
    "\n",
    "Below, you will write a basic function to setup the network using the following criteria:\n",
    "\n",
    "- Uses a `Sequential` model.\n",
    "- Contains two `Dense` layers with 32 units each and `relu` activation function.\n",
    "- Contains a single `Dense` output layer with 1  unit.\n",
    "- Compiles the network using:\n",
    " - `optimizer = 'rmsprop'`\n",
    " - `loss = 'mse'`\n",
    " - `metrics = ['mae']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### QUESTION 14\n",
    "### Complete the function build_regression() below.\n",
    "### This function takes no arguments and returns a compiled Keras model\n",
    "### object according to the criteria above.\n",
    "def build_regression():\n",
    "    '''\n",
    "    Builds a Keras Sequential model with\n",
    "    two Dense layers containing 32 units and \n",
    "    a single linear output layer.\n",
    "    '''\n",
    "    cls = models.Sequential()\n",
    "    cls.add(layers.Dense(units=32, activation='relu', input_shape=(784,)))\n",
    "    cls.add(layers.Dense(units=32, activation='relu'))\n",
    "\n",
    "    cls.add(layers.Dense(units=1,activation='sigmoid'))\n",
    "    cls.compile(loss='mse',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q-14",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Assignment-Contents)\n",
    "\n",
    "---\n",
    "<a id=\"q-housing-eval\"></a>\n",
    "## Question 15: Evaluating the Neural Network for Regression\n",
    "\n",
    "Just as we did with the classification example, we can assess the accuracy of the model using the testing data.\n",
    "\n",
    "+ Prepare a model using the function `build_regression` from the previous question.\n",
    "+ Use the arrays `scaled_train` and `train_targets` to train the model using the `fit` method. Provide the keyword arguments `epochs=10`, and `batch_size=128` to tailor the number of training epochs and the number of random observations drawn in each batch within an epoch.\n",
    "+ Finally, use the `evaluate` method with the testing data `scaled_test` & `test_targets` as input. The output will be a sequence of two values: the loss and the accuracy.\n",
    "+ Assign these two values to `test_loss` and `test_acc` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### QUESTION 15\n",
    "### Build and evaluate your Regression model.\n",
    "### Save the evaluation loss to test_loss and accuracy\n",
    "### to test_acc below.\n",
    "### YOUR SOLUTION HERE:\n",
    "cls.fit(scaled_train, train_targets,\n",
    "          epochs=10,\n",
    "          batch_size=128)\n",
    "score = cls.evaluate(scaled_test, test_targets)\n",
    "test_loss = score[0]\n",
    "test_acc = score[1]\n",
    "print('test_loss: {:9.4g}'.format(test_loss))\n",
    "print('test_acc:  {:9.4g}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q-15",
     "locked": true,
     "points": "6",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Assignment-Contents)\n",
    "\n",
    "---\n",
    "# Constraint Satisfaction Problems and Backtracking\n",
    "\n",
    "\n",
    "In the final portion of this assignment, you'll explore a few [Constraint Satisfaction Problems](https://en.wikipedia.org/wiki/Constraint_satisfaction_problem). From Wikipedia:\n",
    "> Constraint satisfaction problems (CSPs) are mathematical questions defined as a set of objects whose state must satisfy a number of constraints or limitations. CSPs represent the entities in a problem as a homogeneous collection of finite constraints over variables, which is solved by constraint satisfaction methods. CSPs are the subject of intense research in both artificial intelligence and operations research, since the regularity in their formulation provides a common basis to analyze and solve problems of many seemingly unrelated families. CSPs often exhibit high complexity, requiring a combination of heuristics and combinatorial search methods to be solved in a reasonable time. The Boolean satisfiability problem (SAT), the satisfiability modulo theories (SMT) and answer set programming (ASP) can be roughly thought of as certain forms of the constraint satisfaction problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "We will start with the [eight queens puzzle](https://en.wikipedia.org/wiki/Eight_queens_puzzle) or, more precisely, its generalization the $N$ queens puzzle.\n",
    "Given an $N \\times N$ chessboard, determine all the ways in which $N$ queens can be placed on the board so that no queen is threatened by another queen. Remember that queens can move an arbitrary number of spaces along horizontal rows, vertical columns, or diagonally connected squares on the chessboard. So, another way of stating the $N$ queens problem is to place $N$ queens on an $N\\times N$ chessboard so that no two queens occupy the same row or column and so that no two queens lie along any diagonal line (i.e. at 45 degrees) of the board.\n",
    "\n",
    "The $1$-Queens problem has a single, trivial solution. You can enumerate the cases for the $2$-Queens and $3$-Queens solutions to convince yourself that no solutions exist for these cases. For the $4$-Queens problem, here is one solution: \n",
    "<center>\n",
    "    <img src = './assets/sol_4x4_b.png'>\n",
    "</center>\n",
    "\n",
    "To identify positions on the chess board, let the top left square be indexed by `(0,0)` with rows increasing downward and columns increasing to the right. For convenience sake, the positions of the $N$ queens on the board can be represented as a single list: the $k$th entry of the list represents the column location of the queen in row $k$.  For example, to represent the board above, use\n",
    "\n",
    "```python\n",
    ">>> board = [2, 0, 3, 1]\n",
    "```\n",
    "\n",
    "because the queens are positioned at coordinates `(0,2)`, `(1,0)`, `(2,3)`, & `(3,1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#The board above and our representation\n",
    "board = [2, 0, 3, 1]\n",
    "print(board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "To get started, you need to construct a function `is_nqueens_soln` to assess whether a given function is a valid solution of the $N$-Queens problem. Recall that an invalid board has two queens in the same row, the same column, or two queens on any diagonal line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Assignment-Contents)\n",
    "\n",
    "---\n",
    "<a id=\"q-queens-valid\"></a>\n",
    "## Question 16: Verifying a Valid *N*-Queens Chessboard\n",
    "\n",
    "The task here is to complete the function `is_nqueens_soln` that accepts a list of length $N$ as input (the representation of a board as described above).\n",
    "+ Given the list `board` of length $N$ with entries between $0$ and $N-1$, the board is assumed to have a queen at position `(k, board[k])` for `k` $=0,1,\\dotsc,N-1$.\n",
    "+ The function returns `False` if any horizontal line, vertical line, or diagonal line on the $N\\times N$ chessboard contains more than one queen.\n",
    "+ If the entries of `board` are all between $0$ and $N-1$ and the preceding condition fails, the function should return `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### QUESTION 16\n",
    "### Complete the function is_nqueens_soln as described above.\n",
    "def is_nqueens_soln(board):\n",
    "    '''Returns True or False according to whether board is a valid solution of the\n",
    "    N-Queens problem (assuming board is a list of N column coordinates only).\n",
    "    INPUT:\n",
    "       board: a list of length N with column positions of queens in each row.\n",
    "              (note: board should be a permutation of integers 0 through N-1).\n",
    "    OUTPUT:\n",
    "       True or False according to whether board is a valid solution of the N-Queens\n",
    "       problem.\n",
    "    EXAMPLE:\n",
    "    >>> B1 = [1, 3, 0, 2]\n",
    "    >>> is_nqueens_soln(B1)\n",
    "    True\n",
    "    >>> B2 = [2, 0, 3, 3]\n",
    "    >>> is_nqueens_soln(B2)\n",
    "    False\n",
    "    '''\n",
    "    for x in range(len(board)):\n",
    "        return all(abs(x - row) != abs(board[x] - board[row]) and len(board) == len(set(board)) for row in range(x + 1, len(board)))\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "B1 = [1, 3, 0, 2]\n",
    "B2 = [2, 0, 3, 3]\n",
    "print(is_nqueens_soln(B2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q-16",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Assignment-Contents)\n",
    "\n",
    "---\n",
    "You now have the pieces ready to solve the $N$-Queens problem, i.e., to construct the set of all solutions of the $N$-Queens for $N\\ge 4$.\n",
    "\n",
    "You can approach the problem using a general algorithm for solving CSPs called [*backtracking*](https://en.wikipedia.org/wiki/Backtracking). From Wikipedia:\n",
    "\n",
    "> Backtracking is a general algorithm for finding all (or some) solutions to some computational problems, notably constraint satisfaction problems, that incrementally builds candidates to the solutions, and abandons a candidate (\"backtracks\") as soon as it determines that the candidate cannot possibly be completed to a valid solution.\n",
    "\n",
    "\n",
    "The strategy is to enumerate incrementally a set of partial candidates that, in principle, could be completed in various ways to yield all the possible solutions to the given problem. The partial candidates can be conceptually represented as the nodes of a tree structure, the potential search tree. The backtracking algorithm traverses this search tree recursively in a depth-first order. At each node, the algorithm checks for a valid solution. If the current node cannot be completed to a valid solution, the whole subtree rooted at the current node is pruned. Otherwise, the algorithm recursively enumerates all subtrees of from the current node.\n",
    "\n",
    "In the current context, you start with an empty board and the number of queens $N$ to be placed on an $N\\times N$ board."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Assignment-Contents)\n",
    "\n",
    "---\n",
    "<a id=\"q-queens-solving\"></a>\n",
    "## Question 17: Solving the *N*-Queens Problem by Backtracking\n",
    "\n",
    "Your task here is to write a function to solve the $N$-Queens problem by backtracking.\n",
    "+ The function `nqueens_solver` will accept a positive integer $N$ (you can assume that $N\\ge4$).\n",
    "+ Start with a list of known solutions containing an empty list (an empty board)\n",
    "+ Loop over the rows from $0$ to $N-1$:\n",
    "  + Initialize an empty list to accumulate new solutions\n",
    "  + For each column index $k$ from $0$ to $N-1$:\n",
    "    + For each solution list currrently in the list of known solutions:    \n",
    "      + Append the index $k$ to the end of the current solution\n",
    "      + Determine if the modified solution is valid; if so, add it to the list of new solutions\n",
    "  + After looping through all the solutions & all the columns k, overwrite the list of known solutions with the new list of solutions accumulated.\n",
    "+ After looping through all the rows, return the list of solutions accumulated.\n",
    "+ Do not worry about the specific sequence in which the list of solutions is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-31-c018ef4db39b>, line 44)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-31-c018ef4db39b>\"\u001b[0;36m, line \u001b[0;32m44\u001b[0m\n\u001b[0;31m    def isSafe(board, row, col):\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "### QUESTION 17\n",
    "### Complete the function nqueens_solver() below.\n",
    "### This function takes in a value N (size of the board) and uses \n",
    "### backtracking to build a list of all the solutions.\n",
    "def nqueens_solver(N):\n",
    "    '''Backtracking solver for N-Queens problem.\n",
    "    INPUT:\n",
    "      N: positive integer >= 4 (size of chess board)\n",
    "    OUTPUT:\n",
    "      solutions: list of lists of length N (permutations of 0..N-1)\n",
    "    EXAMPLE:\n",
    "    >>> for sol in nqueens_solver(4): print(sol)\n",
    "    [2, 0, 3, 1]\n",
    "    [1, 3, 0, 2]\n",
    "    >>> for sol in nqueens_solver(5): print(sol) # Order not important\n",
    "    [3, 1, 4, 2, 0]\n",
    "    [2, 4, 1, 3, 0]\n",
    "    [4, 2, 0, 3, 1]\n",
    "    [3, 0, 2, 4, 1]\n",
    "    [4, 1, 3, 0, 2]\n",
    "    [0, 3, 1, 4, 2]\n",
    "    [1, 4, 2, 0, 3]\n",
    "    [0, 2, 4, 1, 3]\n",
    "    [2, 0, 3, 1, 4]\n",
    "    [1, 3, 0, 2, 4]\n",
    "    '''\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n",
    "    # Start with a list of known solutions containing an empty list (an empty board)\n",
    "    # Loop over the rows from 0 to N-1:\n",
    "    #     Initialize an empty list to accumulate new solutions\n",
    "    #     For each column index k from 0 to N-1:\n",
    "    #       For each solution list currrently in the list of known solutions:    \n",
    "    #           Append the index k to the end of the current solution\n",
    "    #           Determine if the modified solution is valid;\n",
    "    #               if so, add it to the list of new solutions\n",
    "    #     After looping through all the solutions & all the columns k, overwrite\n",
    "    #     the list of known solutions with the new list of solutions accumulated.\n",
    "    # After looping through all the rows, return the list of solutions accumulated.\n",
    "                \n",
    "#     def isSafe(board, row, col): \n",
    "#         for i in range(col): \n",
    "#             if board[row][i] == 1: \n",
    "#                 return False\n",
    "#         for i, j in zip(range(row, -1, -1),  \n",
    "#                         range(col, -1, -1)): \n",
    "#             if board[i][j] == 1: \n",
    "#                 return False\n",
    "#         for i, j in zip(range(row, N, 1),  \n",
    "#                         range(col, -1, -1)): \n",
    "#             if board[i][j] == 1: \n",
    "#                 return False\n",
    "#         return True\n",
    "#     def solveNQUtil(board, col): \n",
    "#         if col >= N: \n",
    "#             return True\n",
    "#         for i in range(N): \n",
    "#             if isSafe(board, i, col): \n",
    "#                 board[i][col] = 1\n",
    "#                 if solveNQUtil(board, col + 1) == True: \n",
    "#                     return True\n",
    "#                 board[i][col] = 0\n",
    "#         return False\n",
    "#     board = np.zeros([N,N])\n",
    "#     if solveNQUtil(board, 0) == True: \n",
    "#         return board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0.]\n",
      "[1. 0. 0. 0.]\n",
      "[0. 0. 0. 1.]\n",
      "[0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "for sol in nqueens_solver(4): print(sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q-17",
     "locked": true,
     "points": "15",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Assignment-Contents)\n",
    "\n",
    "---\n",
    "\n",
    "An example of a more useful problem one can solve using backtracking is the *flight itinerary problem*. In this problem, you are given a set of tuples of the form *(origin, destination)* where each ordinate in the tuple is an airport code. A starting airport is specifed, but the set of tuples is otherwise not provided in any particular sequence. The goal is to use the list of tuples (flights) provided to recover the sequence of airports visited in sequence making sure to exhaust every tuple in the set provided. Of course, this can be considered a graph teraversal problem where the nodes/vertices are the airports and the edges are the connecting flights.\n",
    "\n",
    "For example, given the following set of flights\n",
    "```\n",
    "    ORD ➔ EWR\n",
    "    YVR ➔ SFO\n",
    "    SFO ➔ ORD\n",
    "    YUL ➔ YVR\n",
    "\n",
    "```\n",
    "\n",
    "and the starting airport `YUL`, you should recover the sequence `YUL ➔ YVR ➔ SFO ➔ ORD ➔ EWR`. In Python, you'll represent the flights as tuples of strings and the final sequence as a single list of strings:\n",
    "```python\n",
    ">>> flights = [('ORD','EWR'), ('YVR','SFO'), ('SFO','ORD'), ('YUL','YVR')]\n",
    ">>> # Eventual itinerary to arrive at...\n",
    ">>> itinerary = ['YUL', 'YVR', 'SFO', 'ORD', 'EWR']\n",
    "```\n",
    "Much like the approach to the $N$-Queens puzzle, you will start with a given itinerary, move through the list and test for valid connections.  If it is, we will continue down the list until we reach a terminal state.  If we reach an invalid move,  we will `.pop()` the move and continue on.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Assignment-Contents)\n",
    "\n",
    "---\n",
    "<a id=\"q-flights-small\"></a>\n",
    "## Question 18: Determining a Flight Itinerary\n",
    "\n",
    "Your task here is to construct a function `get_itinerary` that returns a flight itinerary as described above from a sequence of connecting flights.\n",
    "+ The function accepts two inputs: `flights`, a list of tuples of strings of the form `(origin, destination)` (airport codes) and `itinerary`, a list of strings (airport codes) as input.\n",
    "+ The result returned should be a list of strings like `itinerary` describing a path that traverses all the nodes in `flights`.\n",
    "+ If no such path exists, it should return the Python value `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_itinerary(flights, itinerary):\n",
    "    '''Returns a list of airports (vertices) comprising a traversal of the edges\n",
    "    listed in the input flights.\n",
    "    INPUT:\n",
    "      flight: list of tuples of the form (origin, destination) (i.e., airports)\n",
    "      itinerary: list of destinations (airports)\n",
    "    OUTPUT:\n",
    "      list of airports traversing all edges in flights or None\n",
    "    EXAMPLE:\n",
    "    >>> flights = [('ORD','EWR'), ('YVR','SFO'), ('SFO','ORD'), ('YUL','YVR')]\n",
    "    >>> print(get_itinerary(flights, ['YUL']))\n",
    "    ['YUL', 'YVR', 'SFO', 'ORD', 'EWR']\n",
    "    >>> print(get_itinerary(flights, ['SFO']))\n",
    "    None\n",
    "    '''\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n",
    "    # If flights is empty, return itinerary (you're done)\n",
    "    # Extract the previous stop from the itinerary\n",
    "    # Loop over the list of flights:\n",
    "        # Copy flights excluding current one to mark it as used\n",
    "        # Append the destination (second ordinate) from tuple to itinerary\n",
    "        # When the origin (1st ordinate) matches the previous stop, return\n",
    "        #    the result of a recursive call to get_itinerary using the current\n",
    "        #    itinerary and the copy of flights that excludes the current one.)\n",
    "        # Pop the last entry from the itinerary\n",
    "    # Return None if the loop terminates without returning\n",
    "    if len(flights) ==0:\n",
    "        return itinerary\n",
    "    sch = dict()\n",
    "    \n",
    "    for x in flights:\n",
    "        sch[x[0]] = x[1]\n",
    "\n",
    "    \n",
    "    for x in flights:\n",
    "        temp = itinerary[-1]\n",
    "        if sch[temp] not in itinerary:\n",
    "            itinerary.append(sch[temp])\n",
    "        else:\n",
    "            break\n",
    "        del sch[temp]\n",
    "    if len(itinerary) != len(flights)+1:\n",
    "        return None\n",
    "    return itinerary\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['YUL', 'YVR', 'SFO', 'ORD', 'EWR']\n"
     ]
    }
   ],
   "source": [
    "flights = [('ORD','EWR'), ('YVR','SFO'), ('SFO','ORD'), ('YUL','YVR')]\n",
    "print(get_itinerary(flights, ['YUL']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q-18",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#Assignment-Contents)\n",
    "\n",
    "---\n",
    "## References\n",
    "\n",
    "+ [*Artificial Neural Network* ](https://en.wikipedia.org/wiki/Artificial_neural_network) (Wikipedia)\n",
    "+ [Neural Networks & Deep Learning](http://neuralnetworksanddeeplearning.com/) by Michael Nielsen\n",
    "+ [Keras documentation](https://keras.io)\n",
    "+ [*Constraint Satisfaction Problems*](https://en.wikipedia.org/wiki/Constraint_satisfaction_problem) (Wikipedia)\n",
    "+ [`python-constraint`](https://labix.org/python-constraint)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
