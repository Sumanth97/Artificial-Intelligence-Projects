{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Our standard data imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas.testing as pdt\n",
    "import numpy.testing as npt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Machine Learning Part I: Classification\n",
    "\n",
    "Let's consider the second category of supervised learning problems from our machine learning lectures -- classification problems.  Specifically, we will use `Scikit-Learn` to implement and evaluate classification models on the MNIST handwritten digit dataset.  This is to serve as a reminder and expansion of some earlier work. Later, you will explore how to apply these machine learning ideas to graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<a id = 'questions'></a>\n",
    "\n",
    "+ [**Question 1**: Examining an image](#q1)\n",
    "+ [**Question 2**: Counting the Classes](#q2)\n",
    "+ [**Question 3**: Splitting the Data](#q3)\n",
    "+ [**Question 4**: Binarizing the Target](#q4)\n",
    "+ [**Question 5**: Baseline Confusion Matrix](#q5)\n",
    "+ [**Question 6**: Accuracy Score](#q6)\n",
    "+ [**Question 7**: Probability Table](#q7)\n",
    "+ [**Question 8**: `StandardScaler`](#q8)\n",
    "+ [**Question 9**: `Pipeline`](#q9)\n",
    "+ [**Question 10**: Grid Search](#q10)\n",
    "+ [**Question 11**: Decision Tree](#q11)\n",
    "+ [**Question 12**: Adding Degree Feature](#q12)\n",
    "+ [**Question 13**: Clustering Coefficients](#q13)\n",
    "+ [**Question 14**: Big Influencers](#q14)\n",
    "+ [**Question 15**: Adding distance features (I)](#q15)\n",
    "+ [**Question 16**: Adding distance features (II)](#q16)\n",
    "+ [**Question 17**: `LogisticRegression`](#q17)\n",
    "+ [**Question 18**: Larger Example](#q18)\n",
    "+ [**Question 19**: Structuring the Data](#q19)\n",
    "+ [**Question 20**: Training a Classifier](#q20)\n",
    "+ [**Question 21**: Bagging Classifiers](#q21)\n",
    "+ [**Question 22**: Boosting Classifiers](#q22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Examining the Digits data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 5620\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "Input data shape: (1797, 64)\tTarget data shape: (1797,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "print(digits.DESCR)\n",
    "\n",
    "# Extract data and targets as Numpy arrays\n",
    "X, y = digits.data, digits.target\n",
    "print('Input data shape: {}\\tTarget data shape: {}'.format(X.shape, y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "To get a better feel of what the input data is, let's extract a row of 64 numbers, reshape it into an $8\\times8$ array, and examine the resulting matrix by printing the numeric values & by plotting it as an image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  2. 12.  9.  0.  0.  0.]\n",
      " [ 0.  0. 11. 15. 12.  5.  0.  0.]\n",
      " [ 0.  0. 15.  5.  0. 14.  0.  0.]\n",
      " [ 0.  2. 15.  1.  0.  9.  7.  0.]\n",
      " [ 0.  4. 10.  0.  0.  7.  8.  0.]\n",
      " [ 0.  0. 12.  0.  0.  8. 10.  0.]\n",
      " [ 0.  2. 15.  5. 10. 16.  1.  0.]\n",
      " [ 0.  0.  5. 14. 12.  4.  0.  0.]]\n",
      "y_130 = 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAEFUlEQVR4nO3doYsedBzH8d/tRI6BqCDIQJbGXbi0uGDUIBgMguHCMGhYEgayGbY/waYGZTCwGMSkYBFEZbB6gsiKYbBg2RBFuD3+Aw+L3705X694T/g8T3jzgyvfnc1ms4CeM0/7CwDbiROixAlR4oQocULUM0/68LUzb5/Kf+XuHh6M7r38+f2xrR9+nftt++/eHds6zb5//NXOtr97OSFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBD1xHMMp9XfH/8zunft3Heje1OOL18a23rx1i9jWxVeTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0T9L88xfLb/5eje0Y2rY1uTZwuu/357bOuTWxfGtiq8nBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0RlbqXsHh4Mrv00uLXWS9/eG9s6GVta64Mf3xnb2rv57NjWWmudv/nz6N42Xk6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEZc4xPNp/YWzrrbvvjW2ttdYrD45H96bs/TF3IuHf5x+PbVV4OSFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBCVOcdw9us7Y1sXPnxubGutte6Prs2ZPJGwd/7R2FaFlxOixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlRmXMMu4cHY1vXzn0xtrXWWkeXr45t/fXmw7Gte5c+Hdt64+LrY1trrXUyuradlxOixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oSozK2Uk+PfxraObszdLllrresf3R7b+ubPi2Nbr155f2zr7IM7Y1sVXk6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidE7Ww2m6f9HYAtvJwQJU6IEidEiROixAlR4oSo/wBJqUZwQXFvrAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = 130\n",
    "im = X[k].reshape(8, 8)\n",
    "print(im)\n",
    "plt.imshow(im)\n",
    "plt.axis('off')\n",
    "print('y_{} = {}'.format(k, y[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Apparently, row 130 of the matrix `X` (remember, indexed from zero, this is the 131st row from the top), when reshaped, yields the image above. The corresponding entry of the target vector `y` is $0$ which means that this image is intended to represent the numeral $0$. Whether this is obvious depends on the handwriting of the original author."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#questions)\n",
    "\n",
    "---\n",
    "\n",
    "<a id='q1'></a>\n",
    "### Question 1: Examining a Digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an image of the digit 4.\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "## Plot the image from row 100 of the matrix X.\n",
    "## What numeral does this image represent?\n",
    "## Assign your response as an integer to the identifier ans_1\n",
    "## e.g., ans_1 = 9\n",
    "k = 100\n",
    "y = digits.target\n",
    "ans_1 = '4'\n",
    "image_digit = X[k].reshape(8, 8)\n",
    "plt.imshow(image_digit)\n",
    "plt.show()\n",
    "print('This is an image of the digit {}.'.format(ans_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 01",
     "locked": true,
     "points": "3",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Target Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "In classification problems, the labels (or targets) are *discrete* or *categorical* values (by contrast with regression problems). That being the case, we generally prefer the labelled data to be *balanced*; that is, we prefer having a uniform distribution of labels from which to build our models. For a binary classification problem (i.e., one with two classes), that would mean 50% of the data is from one class and 50% of the data from the other class. For a classification problem with $k$ classes, that would mean each class is represented in $(100 \\div k)$% of the data.\n",
    "\n",
    "Examining the target vector `y` for the MNIST digits data, it appears that each numeral from the sequence `0` through `9` occurs in a random sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 5 5 6 5 0 9 8 9 8 4 1 7 7 3 5 1 0 0 2 2 7 8 2 0 1 2 6 3]\n"
     ]
    }
   ],
   "source": [
    "y = digits.target\n",
    "print(y[31:60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#questions)\n",
    "\n",
    "---\n",
    "\n",
    "<a id='q2'></a>\n",
    "### Question 2: Counting the Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Your task here is to summarize how often each digit from `0` through `9` occurs in the vector `y`. The result be a Pandas Series with the integers `0` though `9` as the index (sorted in increasing order) and the corresponding counts as the data.\n",
    "\n",
    "(Hint: the Pandas Series method `value_counts` can do this easily, as can the Numpy function `unique`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## Graded\n",
    "## Create a Pandas Series with a sorted index \n",
    "## of the numerals 0 through 9. \n",
    "## The corresponding values are the counts of the\n",
    "## occurrences of each digit in the vector y from\n",
    "## the MNIST digits dataset.\n",
    "## Assign the result to the identifier digit_counts\n",
    "series = pd.Series(y)\n",
    "digit_counts = series.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 02",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "From Question 2, it seems the MNIST digits data set is fairly balanced; each of the 10 possible digits occurs roughly 180 times. As with regression problems, we want to divide the data into training and testing sets. The easiest way to do so is using the function `train_test_split` from the Scikit-Learn submodule `sklearn.model_selection` (you can consult the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to learn how to customize the behavior of this function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#questions)\n",
    "\n",
    "---\n",
    "\n",
    "<a id='q3'></a>\n",
    "### Question 3: Splitting the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Your task here is to create a Pandas DataFrame with the digits from $0$ through $9$ in ascending order as the index and with two columns: `train_counts` and `test_counts`. The entries of each row, then, are the number of occurrences of that digit in the training target `y_train` and the testing target `y_test` respectively. Bind the DataFrame to the identifier `split_digit_counts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## GRADED\n",
    "## As in Question 2, count the occurrences of each digit,\n",
    "## but this time in the training & the testing data sets \n",
    "## (i.e., in y_train and y_test).\n",
    "## Assemble the results into a Pandas DataFrame with index\n",
    "## values 0 to 9 (sorted in ascending order) and with two\n",
    "## columns: train_counts & test_counts.\n",
    "## That is, your final DataFrame should have these headings:\n",
    "##        | train_counts | test_counts | \n",
    "## =======================================\n",
    "## Digits | \n",
    "## Assign the DataFrame to the identifier split_digit_counts\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n",
    "split_digit_counts = {'train_counts':pd.Series(y_train).value_counts().sort_index(),\n",
    "                      'test_counts' : pd.Series(y_test).value_counts().sort_index()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 03",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Binary classification\n",
    "\n",
    "To begin, we will turn this into a binary classification problem.  We'll focus specifically on identifying occurrences of the digit `9` wherever it occurs.  For this simpler binary classification problem, we need to change every value in the vector `y` to `1` or `0` according to whether it is `9` or not. That is, replace every occurrence of `9` in the vector  `y` with the value `1`; replace all other values with `0`. This process is called *binarization*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#questions)\n",
    "\n",
    "---\n",
    "\n",
    "<a id='q4'></a>\n",
    "### Question 4: Binarizing the Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Your task here is to create three new arrays: `y_bin`, `y_bin_train`, and `y_bin_test`. These will be binary vectors with `1`s replacing `9`s in `y`, `y_train`, and `y_test` respectively. All other entries will be replaced by `0`s.\n",
    "\n",
    "(Hint: The Numpy function `where` is very useful in this context)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## GRADED\n",
    "## Binarize the vectors y, y_train, &  y_test as described above. \n",
    "## Save the results as y_bin, y_bin_train, and y_bin_test respectively.\n",
    "y1 = np.where(y!=9,0,y)\n",
    "y2 = np.where(y_train!=9,0,y_train)\n",
    "y3 = np.where(y_test!=9,0,y_test)\n",
    "y_bin = np.where(y1==9,1,y1)\n",
    "y_bin_train = np.where(y2==9,1,y2)\n",
    "y_bin_test = np.where(y3==9,1,y3)\n",
    "#print(y_bin,y_bin_train,y_bin_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 04",
     "locked": true,
     "points": "3",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### DummyClassifier\n",
    "\n",
    "To begin, we'll apply the built-in [`DummyClassifier` class from `sklearn.dummy`](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html) to set a baseline for performance of our future models.  This classifier does not actually use the feature matrix `X`; classification decisions are made using the target vector `y` only.  There are a few permissible strategies, but we'll start with the `'most_frequent'` strategy.  That is, the `predict` method always returns the majority class. For our binary digit classification problem, this would be `0` (because the `1` classification is reserved for `9`s and most of the digits are not `9`s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(constant=None, random_state=None, strategy='most_frequent')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy.fit(X_train, y_bin_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Having applied the `fit` method to the training data, we can use the `predict` method to see how this estimator classifies the data. Unsurprisingly, it returns a vector of all `0`s (because that is the majority class for this data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_bin_pred = dummy.predict(X_test)\n",
    "print(y_bin_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "We can compute the fraction of correct classifications using the method `score` with the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fraction of correct classifications is: 0.8933333333333333\n"
     ]
    }
   ],
   "source": [
    "score = dummy.score(X_test, y_bin_test)\n",
    "print('The fraction of correct classifications is: {}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Using `dummy.score` is equivalent to explicitly comparing the entries of `y_bin_pred` to `y_bin_test`, counting the number of correct classifications, and dividing by the number of classifications in total. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fraction of correct classifications is: 0.8933333333333333\n"
     ]
    }
   ],
   "source": [
    "# This is the long way of computing the accuracy score\n",
    "correct_classifications = (y_bin_pred == y_bin_test)\n",
    "score = correct_classifications.sum() / len(correct_classifications)\n",
    "print('The fraction of correct classifications is: {}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "For classification problems, a *confusion matrix* is a more detailed description of the accuracy of a classifier. It contains entries for the actual values as rows and predicted values as columns. This means we have:\n",
    "\n",
    "| $~$ | predicted 0 | predicted 1 |\n",
    "| ---- | ----------- | ---------- |\n",
    "| **actual 0** |  true negative | false positive |\n",
    "| **actual 1** |  false negative | true positive |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "In *Scikit-Learn*, the `confusion_matrix` function takes as arguments the actual labels followed by the predicted labels (labelled in ascending order according to the class labels). From the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html):\n",
    "\n",
    "> `sklearn.metrics.confusion_matrix(y_true, y_pred, labels=None, sample_weight=None)`\n",
    ">\n",
    "> Compute confusion matrix to evaluate the accuracy of a classification\n",
    ">\n",
    "> By definition a confusion matrix $C$ is such that $C_{i,j}$ is equal to the number of observations known to be in group $i$ but predicted to be in group $j$.\n",
    ">\n",
    "> Thus in binary classification, the count of true negatives is $C_{0,0}$, false negatives is $C_{1,0}$, true positives is $C_{1,1}$, and false positives is $C_{0,1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#questions)\n",
    "\n",
    "---\n",
    "\n",
    "<a id='q5'></a>\n",
    "### Question 5: Baseline Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Your task here is to generate the confusion matrix associated with the test data for this digits binary classification problem (i.e., computing which images correspond to the digit `9` and which do not). You can do so explicitly or you can use the function `confusion_matrix` from `sklearn.metrics` according to your preference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[402   0]\n",
      " [ 48   0]]\n"
     ]
    }
   ],
   "source": [
    "## GRADED\n",
    "## Use the training data (X_train, y_bin_train) to fit a DummyClassifier class\n",
    "## instance to the training data. Then, construct a prediction from the test\n",
    "## input features X_test and, by comparing to the test labels y_bin_test,\n",
    "## build the corresponding confusion matrix.\n",
    "## Assign the resulting 2D Numpy array to the identifier bin_confusion_mat\n",
    "from sklearn.metrics import confusion_matrix\n",
    "bin_confusion_mat = confusion_matrix(y_bin_test,y_bin_pred)\n",
    "print(bin_confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 05",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Accuracy\n",
    "\n",
    "The most basic way to assess our performance is to compare how many predictions we were right on out of the total number of observations.  We refer to this as **accuracy**. Using the diagram of our confusion matrix above, we have the formula\n",
    "\n",
    "$$\\text{accuracy} = \\frac{\\text{tp} + \\text{tn}}{\\text{tn} + \\text{tp} + \\text{fn} + \\text{fp}}$$\n",
    "\n",
    "where $\\text{tp}$ is the number of true positives, $\\text{tn}$ is the number of true negatives, $\\text{fp}$ is the number of false positives, and $\\text{fn}$ is the number of false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#questions)\n",
    "\n",
    "---\n",
    "\n",
    "<a id='q6'></a>\n",
    "### Question 6: Accuracy Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Your task here is to compose a function `accuracy_score` that implements the preceding formula. The input to the function is a (previously computed) confusion matrix and the output is an accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## GRADED\n",
    "## Fill in the function accuracy_score below\n",
    "def accuracy_score(confusion_matrix):\n",
    "    '''\n",
    "    This function takes in a confusion matrix \n",
    "    (from a binary classification problem)\n",
    "    and returns the accuracy score.\n",
    "    '''\n",
    "    return ((confusion_matrix[0][0]+confusion_matrix[1][1])/np.sum(confusion_matrix))\n",
    "###\n",
    "### Insert your solution here:\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 06",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Logistic Regression\n",
    "\n",
    "We move on now to estimators for classification problems that actually use the input data (unlike the `DummyClassifier`).  To begin, let's examine the [`LogisticRegression` estimator](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression). In order to determine a logistic regression model, a nonlinear system of equations needs to be solved iteratively; thus, when we instantiate the esitmator, we can specify the solver and the maximum number of iterations. For instance:\n",
    "\n",
    "```python\n",
    ">>> from sklearn.linear_model import LogisticRegression\n",
    ">>> clf = LogisticRegression(solver='newton-cg', max_iter=1000)\n",
    "```\n",
    "Don't worry about what these particular optional parameters mean; other choices exist, but we'll use these for now.\n",
    "\n",
    "As with other *Scikit-Learn*'s estimator classes, the `.fit` and `.predict` methods are used to construct the model and make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(solver = 'newton-cg', max_iter=1000)\n",
    "clf.fit(X_train, y_bin_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "y_pred[335:350] # Some zeros, some ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "For classifications, we can also access the *probabilities* of correctness. That is, for a given observation (i.e., row of `X`), there is not only the class prediction (i.e., corresponding row of `y`), but there are associated *probabilities of that observation belonging to each class*. These probabilites are accessible by the method `predict_proba`; for each observation, this returns a row vector of nonnegative values that sum to 1 where the entry in column $k$ is the probability of belonging to class $k$. Thus, for this binary classification problem, after fitting a classifier (e.g., `LogisticRegression`) to the training data, the method `predict_proba` returns an $n_{\\text{test}}\\times2$ matrix of probabilities (where $n_{\\text{test}}$ is the number of observations in the testing set) whose rows all sum to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99999959e-01, 4.10997660e-08],\n",
       "       [9.99999993e-01, 7.12236813e-09],\n",
       "       [2.96718941e-05, 9.99970328e-01],\n",
       "       [9.99360895e-01, 6.39105017e-04],\n",
       "       [1.00000000e+00, 2.37444895e-13],\n",
       "       [9.99999999e-01, 8.59791277e-10],\n",
       "       [1.00000000e+00, 8.11227664e-20],\n",
       "       [1.00000000e+00, 1.32085932e-18],\n",
       "       [1.00000000e+00, 1.04425587e-13],\n",
       "       [9.99833325e-01, 1.66675467e-04],\n",
       "       [6.20546586e-06, 9.99993795e-01],\n",
       "       [9.99999998e-01, 1.90974001e-09],\n",
       "       [8.90564009e-06, 9.99991094e-01],\n",
       "       [9.99999910e-01, 9.00965024e-08],\n",
       "       [1.00000000e+00, 7.59828642e-11]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Column 0: probability of class 0\n",
    "# Column 1: probability of class 1\n",
    "clf.predict_proba(X_test)[335:350]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#questions)\n",
    "\n",
    "---\n",
    "\n",
    "<a id='q7'></a>\n",
    "### Question 7: Probability Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Your task here is to  construct a function `prob_table` encapsulating the previous computations. It accepts the test data `X_test`, and `y_test`, followed by a classifier (e.g., `DummyClassifier`, `LogisticRegression`, etc.) as arguments. The classifier should already have been fit to data (e.g., `classifier.fit(X_train, y_train)` should already have been invoked). The result returned should be a DataFrame:\n",
    "\n",
    "\n",
    "\n",
    "|  $~$ | prob_0 | prob_1 | predicted_value | actual_value |\n",
    "| ---- | ----------- | ----------- | ------------------ | ------------ |\n",
    "| **0** |  $p_0$ | ($1-{}$ $p_0$) | $y^{\\text{pred}}_0$ | $y^{\\text{test}}_{0}$ |\n",
    "| **1** |  $p_1$ | ($1-{}$ $p_1$) | $y^{\\text{pred}}_1$ | $y^{\\text{test}}_{1}$ |\n",
    "| $\\vdots$ | $\\vdots$ | $\\vdots$ | $\\vdots$ | $\\vdots$ |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "## Complete the prob_table function below\n",
    "def prob_table(X_test, y_test, classifier):\n",
    "    '''\n",
    "    This function takes in a test set X_test, y_test,\n",
    "    and a classifier (that has been fit to data)\n",
    "    It returns a DataFrame with columns below:\n",
    "    | probab_0 | probab_1 | predicted_value | actual_value |\n",
    "    ========================================================\n",
    "    '''\n",
    "    frames = classifier.predict_proba(X_test)\n",
    "    data = {'probab_0' : frames[:,0],'probab_1' : frames[:,1],'predicted_value':classifier.predict(X_test),'actual_value':y_test }\n",
    "    return data\n",
    "###\n",
    "### Insert your solution here:\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'probab_0': array([9.99999997e-01, 2.65727517e-05, 9.99997406e-01, 9.89060759e-01,\n",
      "       1.00000000e+00, 1.00000000e+00, 9.99999940e-01, 9.99999942e-01,\n",
      "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 9.99940867e-01,\n",
      "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
      "       9.99819433e-01, 1.00000000e+00, 9.92599282e-01, 9.99999998e-01,\n",
      "       1.00000000e+00, 9.99999991e-01, 2.80700761e-04, 1.00000000e+00,\n",
      "       9.99999837e-01, 1.00000000e+00, 9.99996687e-01, 1.00000000e+00,\n",
      "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 6.34505193e-05,\n",
      "       1.00000000e+00, 1.00000000e+00, 9.99998542e-01, 1.00000000e+00,\n",
      "       2.44664289e-10, 1.00000000e+00, 9.99999998e-01, 1.00000000e+00,\n",
      "       1.00000000e+00, 1.79973264e-04, 1.00000000e+00, 1.00000000e+00,\n",
      "       1.00000000e+00, 9.99999676e-01, 9.99999999e-01, 9.99995631e-01,\n",
      "       1.00000000e+00, 9.99995525e-01, 9.99743070e-01, 1.00000000e+00,\n",
      "       1.41930677e-01, 9.99999217e-01, 1.00000000e+00, 1.00000000e+00,\n",
      "       2.23106772e-01, 1.00000000e+00, 9.99998410e-01, 1.00000000e+00,\n",
      "       1.00000000e+00, 1.00000000e+00, 9.82185354e-01, 1.00000000e+00,\n",
      "       1.00000000e+00, 9.99999899e-01, 1.00000000e+00, 9.77534598e-01,\n",
      "       1.00000000e+00, 9.99931053e-01, 5.09516275e-07, 9.97889461e-01,\n",
      "       9.99999940e-01, 1.00000000e+00, 9.99999998e-01, 1.00000000e+00,\n",
      "       1.00000000e+00, 1.00000000e+00, 4.67022684e-01, 4.07979682e-01,\n",
      "       4.77232306e-07, 7.37551077e-01, 1.00000000e+00, 1.00000000e+00,\n",
      "       9.97986161e-01, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
      "       1.00000000e+00, 9.09441322e-04, 9.99999999e-01, 9.99999999e-01,\n",
      "       1.00000000e+00, 9.99999799e-01, 5.09758462e-02, 1.00000000e+00,\n",
      "       2.52328660e-05, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
      "       1.00000000e+00, 8.42699025e-01, 9.99992924e-01, 9.99784751e-01,\n",
      "       9.99999982e-01, 1.00000000e+00, 1.00000000e+00, 1.09173545e-03,\n",
      "       1.00000000e+00, 9.99999999e-01, 9.99878566e-01, 1.00000000e+00,\n",
      "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.42824873e-03,\n",
      "       1.00000000e+00, 1.00000000e+00, 9.99711438e-01, 9.99991162e-01,\n",
      "       1.00000000e+00, 1.00000000e+00, 3.80394956e-03, 1.00000000e+00,\n",
      "       1.00000000e+00, 1.00000000e+00, 9.99928136e-01, 1.00000000e+00,\n",
      "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 9.99996614e-01,\n",
      "       1.00000000e+00, 2.56146768e-01, 1.00000000e+00, 1.00000000e+00,\n",
      "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 3.59741792e-01,\n",
      "       1.00000000e+00, 3.69472911e-07, 1.00000000e+00, 1.00000000e+00,\n",
      "       2.85332020e-04, 6.75666666e-03, 1.00000000e+00, 4.70686573e-06,\n",
      "       9.99999997e-01, 9.99999974e-01, 9.99976589e-01, 1.00000000e+00,\n",
      "       1.00000000e+00, 9.99986901e-01, 1.00000000e+00, 1.00000000e+00,\n",
      "       9.99972574e-01, 1.55321414e-05, 9.99997689e-01, 7.52036830e-01,\n",
      "       1.00000000e+00, 1.00000000e+00, 3.33845476e-01, 9.99999991e-01,\n",
      "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
      "       9.99999999e-01, 6.54409653e-01, 3.91233547e-05, 1.00000000e+00,\n",
      "       1.00000000e+00, 9.99998636e-01, 1.00000000e+00, 1.00000000e+00,\n",
      "       9.99468038e-01, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
      "       9.99999000e-01, 5.90299046e-06, 9.99998088e-01, 1.00000000e+00,\n",
      "       9.99807013e-01, 1.00000000e+00, 1.00000000e+00, 9.99999663e-01,\n",
      "       1.00000000e+00, 1.79850891e-08, 3.24443569e-08, 1.00000000e+00,\n",
      "       1.00000000e+00, 1.00000000e+00, 9.99780774e-01, 1.00000000e+00,\n",
      "       9.97478217e-01, 1.00000000e+00, 1.00000000e+00, 9.99983399e-01,\n",
      "       9.96528853e-01, 1.62946168e-09, 9.99999938e-01, 9.99989924e-01,\n",
      "       1.00000000e+00, 9.10715319e-05, 1.00000000e+00, 9.97771389e-01,\n",
      "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
      "       7.35816164e-09, 1.00000000e+00, 1.00000000e+00, 9.99999993e-01,\n",
      "       1.00000000e+00, 1.00000000e+00, 9.99999851e-01, 1.00000000e+00,\n",
      "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
      "       1.00000000e+00, 9.99999998e-01, 1.00000000e+00, 9.99765352e-01,\n",
      "       9.96635321e-01, 1.00000000e+00, 9.99999188e-01, 1.00000000e+00,\n",
      "       1.00000000e+00, 9.65785776e-01, 8.71671789e-02, 9.99999993e-01,\n",
      "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 9.99986154e-01,\n",
      "       1.00000000e+00, 9.99942462e-01, 1.00000000e+00, 1.00000000e+00,\n",
      "       9.99999484e-01, 9.99846146e-01, 9.99999841e-01, 9.99481143e-01,\n",
      "       1.95876890e-04, 3.33409560e-01, 9.99998293e-01, 1.00000000e+00,\n",
      "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 9.99995809e-01,\n",
      "       1.00000000e+00, 9.99999864e-01, 9.99957433e-01, 9.99998937e-01,\n",
      "       1.00000000e+00, 9.99999841e-01, 7.79576794e-01, 9.99999995e-01,\n",
      "       9.92567363e-01, 9.99996115e-01, 1.00000000e+00, 9.62796684e-01,\n",
      "       1.00000000e+00, 9.97719117e-01, 1.00000000e+00, 1.00000000e+00,\n",
      "       9.99997581e-01, 1.00000000e+00, 9.99999934e-01, 1.00000000e+00,\n",
      "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 9.99999685e-01,\n",
      "       1.00000000e+00, 9.99892704e-01, 1.29736422e-09, 1.00000000e+00,\n",
      "       1.00000000e+00, 1.00000000e+00, 9.93792648e-01, 1.07978419e-07,\n",
      "       2.65154348e-07, 9.99980277e-01, 9.99999938e-01, 9.99523102e-01,\n",
      "       9.99999997e-01, 1.00000000e+00, 9.99999815e-01, 9.99999987e-01,\n",
      "       9.99982606e-01, 9.99999856e-01, 1.00000000e+00, 1.00000000e+00,\n",
      "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
      "       9.99999934e-01, 1.00000000e+00, 9.99999074e-01, 1.00000000e+00,\n",
      "       9.99999981e-01, 1.00000000e+00, 9.99999998e-01, 9.99163756e-01,\n",
      "       1.00000000e+00, 1.00000000e+00, 9.99981625e-01, 1.00000000e+00,\n",
      "       1.00000000e+00, 9.99866144e-01, 1.00000000e+00, 9.99996521e-01,\n",
      "       9.99999999e-01, 1.00000000e+00, 9.99996603e-01, 9.99999980e-01,\n",
      "       1.00000000e+00, 9.85285976e-01, 1.00000000e+00, 1.00000000e+00,\n",
      "       9.99992181e-01, 9.99998848e-01, 9.99999453e-01, 1.00000000e+00,\n",
      "       9.99999289e-01, 1.00000000e+00, 9.99999150e-01, 9.99999959e-01,\n",
      "       9.99999993e-01, 2.96718941e-05, 9.99360895e-01, 1.00000000e+00,\n",
      "       9.99999999e-01, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
      "       9.99833325e-01, 6.20546586e-06, 9.99999998e-01, 8.90564009e-06,\n",
      "       9.99999910e-01, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
      "       6.41478523e-01, 9.99999996e-01, 9.99998675e-01, 1.00000000e+00,\n",
      "       9.99999995e-01, 9.99999474e-01, 9.99997559e-01, 9.99795077e-01,\n",
      "       1.00000000e+00, 1.00000000e+00, 9.99999986e-01, 1.00000000e+00,\n",
      "       9.99997323e-01, 9.31885837e-01, 9.99999995e-01, 9.99999988e-01,\n",
      "       1.00000000e+00, 9.99999997e-01, 1.00000000e+00, 9.99999999e-01,\n",
      "       1.00000000e+00, 1.00000000e+00, 2.26920759e-01, 1.00000000e+00,\n",
      "       9.99996787e-01, 1.00000000e+00, 9.99999144e-01, 9.99952355e-01,\n",
      "       1.00000000e+00, 9.99999998e-01, 9.99997180e-01, 9.99999989e-01,\n",
      "       4.18094600e-07, 9.99998600e-01, 9.99900228e-01, 1.00000000e+00,\n",
      "       9.99999785e-01, 1.00000000e+00, 9.99999972e-01, 9.99997971e-01,\n",
      "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
      "       9.99999998e-01, 1.00000000e+00, 9.99998939e-01, 9.99999966e-01,\n",
      "       1.00000000e+00, 1.00000000e+00, 9.99999997e-01, 1.00000000e+00,\n",
      "       9.99994344e-01, 9.99999999e-01, 1.00000000e+00, 9.99465355e-01,\n",
      "       9.99999250e-01, 9.99999997e-01, 2.03810447e-03, 1.00000000e+00,\n",
      "       9.99997322e-01, 9.99999901e-01, 1.00000000e+00, 8.53340388e-01,\n",
      "       9.99933362e-01, 1.00000000e+00, 9.99603904e-01, 8.84953432e-08,\n",
      "       9.99629986e-01, 1.00000000e+00, 1.26192925e-05, 1.00000000e+00,\n",
      "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 6.87563850e-09,\n",
      "       1.00000000e+00, 9.99930900e-01, 9.99999972e-01, 1.00000000e+00,\n",
      "       9.99998720e-01, 1.00000000e+00, 9.99550138e-01, 1.74291203e-08,\n",
      "       1.00000000e+00, 1.32287250e-05, 9.99997533e-01, 1.00000000e+00,\n",
      "       1.00000000e+00, 9.99388594e-01, 9.99999964e-01, 9.24142006e-01,\n",
      "       1.00000000e+00, 9.99999997e-01, 1.00000000e+00, 1.00000000e+00,\n",
      "       1.00000000e+00, 1.00000000e+00]), 'probab_1': array([3.24563203e-09, 9.99973427e-01, 2.59355566e-06, 1.09392415e-02,\n",
      "       5.86533900e-13, 4.72906630e-10, 6.04606491e-08, 5.75225121e-08,\n",
      "       5.33139238e-14, 1.51072770e-29, 5.74723933e-14, 5.91333031e-05,\n",
      "       5.12869172e-17, 2.80837374e-11, 3.52078652e-29, 4.95193019e-20,\n",
      "       1.80567430e-04, 3.98031663e-10, 7.40071842e-03, 2.07039366e-09,\n",
      "       1.35646323e-20, 8.88056220e-09, 9.99719299e-01, 5.72144776e-16,\n",
      "       1.62509923e-07, 7.66313071e-24, 3.31339253e-06, 5.12827893e-11,\n",
      "       4.22399419e-20, 7.92054264e-15, 1.06032304e-32, 9.99936549e-01,\n",
      "       3.02736650e-13, 5.15609782e-28, 1.45750442e-06, 1.87269163e-18,\n",
      "       1.00000000e+00, 5.95989157e-31, 2.29387817e-09, 1.05162789e-19,\n",
      "       3.01940454e-13, 9.99820027e-01, 4.47129786e-16, 2.78756982e-10,\n",
      "       3.88143435e-24, 3.23987317e-07, 7.61014725e-10, 4.36898607e-06,\n",
      "       3.85607363e-24, 4.47540087e-06, 2.56930296e-04, 1.33234770e-14,\n",
      "       8.58069323e-01, 7.83371915e-07, 1.21030060e-11, 1.05190923e-10,\n",
      "       7.76893228e-01, 5.79586955e-19, 1.59040448e-06, 2.19953056e-10,\n",
      "       1.97281373e-14, 3.66206765e-25, 1.78146461e-02, 1.50666457e-17,\n",
      "       1.68214098e-28, 1.00934279e-07, 5.49530210e-19, 2.24654022e-02,\n",
      "       6.27998975e-15, 6.89470859e-05, 9.99999490e-01, 2.11053919e-03,\n",
      "       6.01251476e-08, 1.67920925e-12, 1.66447464e-09, 2.63839468e-12,\n",
      "       3.54973582e-25, 2.23871304e-12, 5.32977316e-01, 5.92020318e-01,\n",
      "       9.99999523e-01, 2.62448923e-01, 1.51998258e-21, 6.02249784e-11,\n",
      "       2.01383881e-03, 7.24380001e-11, 2.29074252e-13, 2.28919847e-16,\n",
      "       1.70177639e-21, 9.99090559e-01, 1.49201745e-09, 1.04351222e-09,\n",
      "       1.30675365e-12, 2.00821512e-07, 9.49024154e-01, 4.16384872e-15,\n",
      "       9.99974767e-01, 3.48887813e-18, 3.09702372e-13, 3.83872057e-21,\n",
      "       8.62042265e-28, 1.57300975e-01, 7.07639891e-06, 2.15249333e-04,\n",
      "       1.75807081e-08, 7.11449838e-12, 2.97364161e-12, 9.98908265e-01,\n",
      "       1.43372431e-27, 1.36742244e-09, 1.21433934e-04, 7.70858107e-17,\n",
      "       2.05534654e-24, 8.62100727e-33, 1.15652178e-14, 9.98571751e-01,\n",
      "       8.54839578e-13, 4.43580370e-11, 2.88562270e-04, 8.83780571e-06,\n",
      "       3.47703517e-14, 4.00402235e-16, 9.96196050e-01, 3.68331359e-13,\n",
      "       4.64963948e-12, 1.94256789e-16, 7.18644935e-05, 1.80144341e-18,\n",
      "       8.15987803e-13, 3.77477171e-10, 3.33115219e-20, 3.38562672e-06,\n",
      "       5.79945498e-14, 7.43853232e-01, 8.93258692e-11, 1.21044245e-17,\n",
      "       1.00130432e-19, 4.88549222e-19, 3.09736552e-15, 6.40258208e-01,\n",
      "       1.01560969e-11, 9.99999631e-01, 1.20744143e-26, 1.40006382e-14,\n",
      "       9.99714668e-01, 9.93243333e-01, 1.32695113e-21, 9.99995293e-01,\n",
      "       2.77162612e-09, 2.60940139e-08, 2.34109760e-05, 9.00780618e-20,\n",
      "       6.57454901e-20, 1.30985554e-05, 7.47374806e-18, 6.72728509e-24,\n",
      "       2.74255084e-05, 9.99984468e-01, 2.31092406e-06, 2.47963170e-01,\n",
      "       9.94163341e-21, 1.99289825e-14, 6.66154524e-01, 9.45947065e-09,\n",
      "       2.43390328e-27, 3.79470815e-14, 5.02847468e-11, 3.77662679e-22,\n",
      "       6.40076447e-10, 3.45590347e-01, 9.99960877e-01, 2.62623362e-10,\n",
      "       3.91700067e-30, 1.36360068e-06, 5.96560567e-14, 3.76594133e-10,\n",
      "       5.31962239e-04, 1.22310046e-10, 2.72141985e-23, 2.39535414e-19,\n",
      "       9.99895013e-07, 9.99994097e-01, 1.91211106e-06, 7.67692579e-12,\n",
      "       1.92987003e-04, 3.60667671e-12, 3.79507603e-13, 3.37452496e-07,\n",
      "       8.37027457e-19, 9.99999982e-01, 9.99999968e-01, 1.93965898e-19,\n",
      "       5.60646071e-20, 1.47405036e-32, 2.19225724e-04, 3.15056394e-12,\n",
      "       2.52178348e-03, 8.02487651e-17, 4.19514189e-12, 1.66009148e-05,\n",
      "       3.47114670e-03, 9.99999998e-01, 6.17102974e-08, 1.00756641e-05,\n",
      "       1.22276675e-14, 9.99908928e-01, 6.44546772e-24, 2.22861130e-03,\n",
      "       3.28318203e-13, 4.43297586e-10, 2.77295484e-28, 5.20538307e-23,\n",
      "       9.99999993e-01, 2.96680229e-15, 2.69414649e-12, 6.74425267e-09,\n",
      "       5.34619012e-12, 1.89364037e-15, 1.48638277e-07, 1.70621890e-20,\n",
      "       4.68810963e-13, 1.77958613e-10, 1.40107668e-26, 4.15970258e-20,\n",
      "       1.43073240e-29, 2.08799469e-09, 8.80159549e-21, 2.34647520e-04,\n",
      "       3.36467919e-03, 7.94389260e-14, 8.11704137e-07, 1.33073387e-18,\n",
      "       1.07641369e-15, 3.42142241e-02, 9.12832821e-01, 6.74648288e-09,\n",
      "       1.04082507e-29, 1.38845533e-18, 8.18512149e-16, 1.38461138e-05,\n",
      "       2.45593373e-13, 5.75378935e-05, 4.31849844e-10, 3.05985674e-20,\n",
      "       5.15841764e-07, 1.53854402e-04, 1.58730335e-07, 5.18857396e-04,\n",
      "       9.99804123e-01, 6.66590440e-01, 1.70675522e-06, 1.28807567e-14,\n",
      "       3.54552545e-14, 3.30536657e-20, 2.12737604e-11, 4.19060499e-06,\n",
      "       9.18816832e-26, 1.36342715e-07, 4.25674943e-05, 1.06323060e-06,\n",
      "       9.41723626e-27, 1.59181821e-07, 2.20423206e-01, 4.80802817e-09,\n",
      "       7.43263731e-03, 3.88501871e-06, 1.80612644e-11, 3.72033156e-02,\n",
      "       3.02486605e-25, 2.28088258e-03, 2.04310106e-15, 2.53134621e-12,\n",
      "       2.41866637e-06, 2.11512190e-11, 6.59758176e-08, 1.39518219e-19,\n",
      "       2.18877691e-10, 2.70794554e-10, 1.15720697e-10, 3.14667145e-07,\n",
      "       1.15346775e-24, 1.07295959e-04, 9.99999999e-01, 2.23629779e-17,\n",
      "       4.72205072e-10, 4.73082530e-15, 6.20735196e-03, 9.99999892e-01,\n",
      "       9.99999735e-01, 1.97233260e-05, 6.21947464e-08, 4.76897595e-04,\n",
      "       3.08701170e-09, 7.62069424e-21, 1.84933525e-07, 1.30327050e-08,\n",
      "       1.73937422e-05, 1.44090795e-07, 3.06509076e-28, 3.16662185e-14,\n",
      "       1.15213437e-11, 1.66002273e-11, 6.50520096e-13, 5.09179962e-26,\n",
      "       6.61512341e-08, 8.99929363e-21, 9.25932945e-07, 2.90613676e-12,\n",
      "       1.87583940e-08, 2.71733783e-21, 2.33847718e-09, 8.36244460e-04,\n",
      "       6.50237170e-14, 3.70299659e-25, 1.83745508e-05, 7.05879871e-17,\n",
      "       1.83009054e-18, 1.33856377e-04, 1.06104464e-15, 3.47877586e-06,\n",
      "       7.76400001e-10, 6.74389299e-17, 3.39706898e-06, 1.98895466e-08,\n",
      "       2.49086678e-13, 1.47140242e-02, 6.18849666e-21, 3.90028515e-17,\n",
      "       7.81911092e-06, 1.15212012e-06, 5.47295156e-07, 3.90933482e-16,\n",
      "       7.11185751e-07, 1.94888998e-22, 8.49535408e-07, 4.10997660e-08,\n",
      "       7.12236813e-09, 9.99970328e-01, 6.39105017e-04, 2.37444895e-13,\n",
      "       8.59791277e-10, 8.11227664e-20, 1.32085932e-18, 1.04425587e-13,\n",
      "       1.66675467e-04, 9.99993795e-01, 1.90974001e-09, 9.99991094e-01,\n",
      "       9.00965024e-08, 7.59828642e-11, 1.96896826e-12, 7.73245789e-23,\n",
      "       3.58521477e-01, 3.84481904e-09, 1.32451791e-06, 6.44959587e-24,\n",
      "       5.32302801e-09, 5.25845304e-07, 2.44088029e-06, 2.04922836e-04,\n",
      "       3.27937186e-16, 1.34110780e-11, 1.41756900e-08, 2.29670359e-10,\n",
      "       2.67677821e-06, 6.81141631e-02, 5.29154735e-09, 1.16732245e-08,\n",
      "       3.64517558e-30, 3.11700277e-09, 7.96140820e-15, 5.12887130e-10,\n",
      "       2.35129069e-29, 1.68250529e-12, 7.73079241e-01, 1.37923717e-23,\n",
      "       3.21324453e-06, 5.31459442e-15, 8.56379392e-07, 4.76453062e-05,\n",
      "       3.87582413e-29, 2.23409278e-09, 2.82020520e-06, 1.09014255e-08,\n",
      "       9.99999582e-01, 1.39955929e-06, 9.97722011e-05, 7.78056435e-12,\n",
      "       2.14952018e-07, 3.10986680e-19, 2.80631968e-08, 2.02932836e-06,\n",
      "       3.50016435e-13, 4.24837354e-13, 1.80987033e-15, 1.22522174e-12,\n",
      "       2.42840170e-09, 1.82946984e-12, 1.06095643e-06, 3.44699630e-08,\n",
      "       8.99397609e-17, 1.79744537e-32, 2.63223595e-09, 1.57841715e-23,\n",
      "       5.65604722e-06, 5.40269760e-10, 1.51704111e-29, 5.34645069e-04,\n",
      "       7.49960225e-07, 2.80239903e-09, 9.97961896e-01, 5.21010884e-26,\n",
      "       2.67847985e-06, 9.93148685e-08, 1.90811171e-16, 1.46659612e-01,\n",
      "       6.66380619e-05, 2.16658663e-11, 3.96096335e-04, 9.99999912e-01,\n",
      "       3.70013527e-04, 6.22133405e-15, 9.99987381e-01, 3.18332982e-14,\n",
      "       1.60472991e-22, 2.05744012e-10, 9.52227481e-12, 9.99999993e-01,\n",
      "       1.83850362e-16, 6.90997340e-05, 2.75567211e-08, 7.59118228e-15,\n",
      "       1.28011662e-06, 1.06788205e-22, 4.49862060e-04, 9.99999983e-01,\n",
      "       5.73532331e-31, 9.99986771e-01, 2.46673104e-06, 1.97849910e-12,\n",
      "       5.89422951e-17, 6.11405974e-04, 3.57564746e-08, 7.58579939e-02,\n",
      "       1.46767982e-10, 3.27297784e-09, 1.64123531e-21, 4.35372382e-16,\n",
      "       2.01579082e-17, 2.37061146e-19]), 'predicted_value': array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'actual_value': array([6, 9, 3, 7, 2, 1, 5, 2, 5, 2, 1, 9, 4, 0, 4, 2, 3, 7, 8, 8, 4, 3,\n",
      "       9, 7, 5, 6, 3, 5, 6, 3, 4, 9, 1, 4, 4, 6, 9, 4, 7, 6, 6, 9, 1, 3,\n",
      "       6, 1, 3, 0, 6, 5, 5, 1, 9, 5, 6, 0, 9, 0, 0, 1, 0, 4, 5, 2, 4, 5,\n",
      "       7, 0, 7, 5, 9, 5, 5, 4, 7, 0, 4, 5, 5, 9, 9, 0, 2, 3, 8, 0, 6, 4,\n",
      "       4, 9, 1, 2, 8, 3, 5, 2, 9, 0, 4, 4, 4, 3, 5, 3, 1, 3, 5, 9, 4, 2,\n",
      "       7, 7, 4, 4, 1, 9, 2, 7, 8, 7, 2, 6, 9, 4, 0, 7, 2, 7, 5, 8, 7, 5,\n",
      "       7, 7, 0, 6, 6, 4, 2, 8, 0, 9, 4, 6, 9, 9, 6, 9, 0, 3, 5, 6, 6, 0,\n",
      "       6, 4, 3, 9, 3, 9, 7, 2, 9, 0, 4, 5, 3, 6, 5, 9, 9, 8, 4, 2, 1, 3,\n",
      "       7, 7, 2, 2, 3, 9, 8, 0, 3, 2, 2, 5, 6, 9, 9, 4, 1, 5, 4, 2, 3, 6,\n",
      "       4, 8, 5, 9, 5, 7, 8, 9, 4, 8, 1, 5, 4, 4, 9, 6, 1, 8, 6, 0, 4, 5,\n",
      "       2, 7, 4, 6, 4, 5, 6, 0, 3, 2, 3, 6, 7, 1, 5, 1, 4, 7, 6, 8, 8, 5,\n",
      "       5, 1, 6, 2, 8, 8, 9, 9, 7, 6, 2, 2, 2, 3, 4, 8, 8, 3, 6, 0, 9, 7,\n",
      "       7, 0, 1, 0, 4, 5, 1, 5, 3, 6, 0, 4, 1, 0, 0, 3, 6, 5, 9, 7, 3, 5,\n",
      "       5, 9, 9, 8, 5, 3, 3, 2, 0, 5, 8, 3, 4, 0, 2, 4, 6, 4, 3, 4, 5, 0,\n",
      "       5, 2, 1, 3, 1, 4, 1, 1, 7, 0, 1, 5, 2, 1, 2, 8, 7, 0, 6, 4, 8, 8,\n",
      "       5, 1, 8, 4, 5, 8, 7, 9, 8, 5, 0, 6, 2, 0, 7, 9, 8, 9, 5, 2, 7, 7,\n",
      "       1, 8, 7, 4, 3, 8, 3, 5, 6, 0, 0, 3, 0, 5, 0, 0, 4, 1, 2, 8, 4, 5,\n",
      "       9, 6, 3, 1, 8, 8, 4, 2, 3, 8, 9, 8, 8, 5, 0, 6, 3, 3, 7, 1, 6, 4,\n",
      "       1, 2, 1, 1, 6, 4, 7, 4, 8, 3, 4, 0, 5, 1, 9, 4, 5, 7, 6, 3, 7, 0,\n",
      "       5, 9, 7, 5, 9, 7, 4, 2, 1, 9, 0, 7, 5, 3, 3, 6, 3, 9, 6, 9, 5, 0,\n",
      "       1, 5, 5, 8, 3, 3, 6, 2, 6, 5])}\n"
     ]
    }
   ],
   "source": [
    "print(prob_table(X_test, y_test,clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 07",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Standardizing the data\n",
    "\n",
    "Prior to fitting a given estimator to data, we usually want to *standardize* the data. This is usually done by replacing features with their respective *z-scores*. That is, we translate and rescale the data so that the $k$th feature $x_k$ is replaced according to the substitution $x_k \\leftarrow (x_k - \\mu_k) / \\sigma_k$ where $\\mu_k$ is the (empirical) mean of the $k$th feature and $\\sigma_k$ is the (empirical) standard deviation of the $k$th feature. When working with testing and training data sets, the values of $\\mu_k$ and $\\sigma_k$ are determined using the training data and those same values are used to standardize the test data when validating the resulting estimator.\n",
    "\n",
    "All of the above can be achieved using the [`StandardScaler` class from `sklearn.preprocessing`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html). Instances of this class can accept a matrix of observations and return the corresponding z-scores down each column (remember, the rows are observations and the columns are the features). The resulting `StandardScalar` object, once fit to the training data, can be used to transform the testing data as well.\n",
    "\n",
    "Here's an example of how to use the `StandardScaler` class to transform data:\n",
    "```python\n",
    ">>> from sklearn.preprocessing import StandardScaler\n",
    ">>> data = np.array([[0, 0], [0, 1], [1, 1], [1, 1]]) # Create 4x2 array of data\n",
    ">>> scaler = StandardScaler() # Instantiate StandardScaler object\n",
    ">>> scaler.fit(data)          # Use columns from data to define transformation\n",
    ">>> print(scaler.mean_)       # means of 2 columns from data\n",
    "[0.5  0.75]\n",
    ">>> print(scaler.var_)        # variances of 2 columns from data\n",
    ">>> print(scaler.transform(data))  # Applying transformation to data\n",
    "[[-1.         -1.73205081]\n",
    " [-1.          0.57735027]\n",
    " [ 1.          0.57735027]\n",
    " [ 1.          0.57735027]]\n",
    ">>> print(scaler.transform([[2, 2]]))  # Applying transformation to new observation\n",
    "[[3.         2.88675135]]\n",
    "```\n",
    "As an alternative to applying the methods `fit` and then `transform`, there is a `fit_transform` method that combines the two into a single step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#questions)\n",
    "\n",
    "---\n",
    "\n",
    "<a id='q8'></a>\n",
    "### Question 8: `StandardScaler`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Your task here is to standardize the data using the `StandardScalar` class as above. You'll define the transformation to the training feature matrix `X_train` with the `fit` method. You'll apply the resulting transformation to `X_train` and `X_test` to yield standardized data for both the training and testing sets. From there, you'll define a `LogisticRegression` classifier and fit that to the standardized training feature matrix and the binary labels `y_bin_train`. Finally, you'll use the function `prob_table` from Question 7 to create a DataFrame `prob_table_standardized` that shows the classifications using the standardized test data as compared to the actual classifications with their corresponding probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "### GRADED\n",
    "## Use the StandardScalar class to transform the training & test data\n",
    "## X_train & X_test. Then, instantiate a LogisticRegression and fit\n",
    "## it to the transformed training data. Finally, use the resulting\n",
    "## classifier and the transformed test data as inputs to the prob_table\n",
    "## function from Question 19.\n",
    "## Assign the resulting DataFrame to prob_table_standardized\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "train_transform = scaler.transform(X_train)\n",
    "trest_transform = scaler.transform(X_test)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(train_transform,y_bin_train)\n",
    "prob_table_standardized = prob_table(trest_transform, y_test, lr)\n",
    "#print(prob_table_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.99999959e-01 9.99999993e-01 2.96718941e-05 9.99360895e-01\n",
      " 1.00000000e+00 9.99999999e-01 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 9.99833325e-01 6.20546586e-06 9.99999998e-01\n",
      " 8.90564009e-06 9.99999910e-01 1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict_proba(X_test)[335:350][:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 08",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Using Pipelines\n",
    "\n",
    "Many modeling tasks involve the combination of preprocessing steps that are fed into an estimator.  As such, *Scikit-Learn* comes with a handy `Pipeline` module that allows us to combine *transformers* (e.g., `StandardScaler`) and *estimators* (e.g., `LinearRegression`, `LogisticRegression`, etc.) in a single object.  The `Pipeline` expects a sequence of transformers -- objects that have methods `fit`, `transform`, & `fit_transform` -- and ends with an estimator -- objects that have methods `fit`, `predict`, & `fit_predict`.  For example, we could have a `Pipeline` that scales our data as in Question 20 and subsequently fits a `LogisticRegression` model as follows:\n",
    "\n",
    "```python\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('clf', LogisticRegression(max_iter=1000, solver='newton-cg'))])\n",
    "```\n",
    "\n",
    "Notice that the `Pipeline` object is instantiated using a list of tuples; all the tuples consist of a string identifier followed by an instance of one of Scikit-Learn's transformer classes except the last tuple (which has an estimator class instance instead). The resulting `Pipeline` object bechaves like an estimator (i.e., it has methods `fit`. `predict`, and `fit_predict`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#questions)\n",
    "\n",
    "---\n",
    "\n",
    "<a id='q9'></a>\n",
    "### Question 9: `Pipeline`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Your task here is to construct a `Pipeline` object as described above for a binary classification problem. We'll load and prepare the data `X` and `y` for you (`y` is a binary vector distinguishing the digit `3` from all other digits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADING\n",
    "## Construct a pipeline object called pipe combining a StandardScaler transformation with\n",
    "## a LogisticRegression estimator. Fit the resulting pipelined estimator's to the training\n",
    "## data X_train & y_train (provided) and construct a vector y_pred using the predict method\n",
    "## of the Pipeline.\n",
    "## Be sure your solution binds a suitable Pipeline object to the identifier pipe &\n",
    "## a Numpy array to the identifier y_pred.\n",
    "from sklearn.pipeline import Pipeline\n",
    "digits = load_digits()\n",
    "X, y = digits.data, np.where(digits.target==3, 1, 0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('clf', LogisticRegression(max_iter=1000, solver='newton-cg'))])\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 09",
     "locked": true,
     "points": "15",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Regularization\n",
    "\n",
    "As with linear regression, we can use *regularization* in conjunction with logistic regression. That is, we can modify the objective function being minimized to construct the estimator with a penalty term. From the [Scikit-Learn User guide](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression):\n",
    "\n",
    "> As an optimization problem, binary class $L2$ penalized logistic regression minimizes the following cost function:\n",
    ">    $$\\min_{w,c} \\frac{1}{2}w^Tw + C\\sum_{i=1}^{n}\\log\\left(\\exp\\left(-y_i\\left(X_{i}^{T}w+c\\right)\\right)+1\\right).$$\n",
    "> Similarly, $L1$ regularized logistic regression solves the following optimization problem\n",
    ">    $$\\min_{w,c} \\left\\|w\\right\\|_{1} + C\\sum_{i=1}^{n}\\log\\left(\\exp\\left(-y_i\\left(X_{i}^{T}w+c\\right)\\right)+1\\right).$$\n",
    "> Note that, in this notation, it's assumed that the observation $y_i$ takes values in the set $\\{-1,1\\}$ at trial.\n",
    "\n",
    "Ignoring the mathematical details of all the terms in these objective functions, the regularization parameter in the Scikit-Learn `LogisticRegression` estimator is labelled `C` consistent with the parameter $C$ in the equations above. Loosely speaking, $C$ controls the relative importance of the penalty term (the terms $w^Tw$ or $\\|w\\|_1$ in each of the objective functions) and the unpenalized objective (the expression preceded by $C$). So, when $C$ is small, the coefficients in $w$ that determine the logistic regressor are penalized more strongly forcing the penalty term to be smaller.\n",
    "\n",
    "In practice with *Scikit-Learn*, we instantiate a `LogisticRegression` instance using the keyword option `C`. For our purposes, this means (when we use the `max_iter` and `solver` parameters as before) the following code for instantiation:\n",
    "\n",
    "```python\n",
    ">>> clf = LogisticRegression(C=100, max_iter=1000, solver='newton-cg')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#questions)\n",
    "\n",
    "---\n",
    "\n",
    "<a id='q10'></a>\n",
    "### Question 10: Grid Search\n",
    "\n",
    "Your task here is to embed the computation from Question 21 in a function called `log_reg_gridsearch`. The function `log_reg_gridsearch` accepts as input arguments the input feature matrix `X`, the target vector `y`, and a list `C_vals` of positive scalar values (for the regularization parameter $C$ in regularized logistic regression).\n",
    "\n",
    "The input data is split into training & test sets with a fixed random parameter 42 (done for you).\n",
    "From there, your function will loop over the values `c_val` within the list `C_vals`. For each value, you will:\n",
    "* instantiate a `Pipeline` object with a `StandardScaler` object followed by a `LogisticRegression` object\n",
    "* the `LogisticRegression` estimator is instantiated with keyword arguments `solver='newton-cg'`, `max_iter=1000`, and `C=c_val`\n",
    "* the `Pipeline` is fit to the training data `X_train` & `y_train`\n",
    "* the `Pipeline` is used to predict target values from the test data `X_test`\n",
    "* the accuracy score (as computed using the estimator `score` method or the function `accuracy_score`\n",
    "  from Question 18)\n",
    "\n",
    "The result returned by the function is a DataFrame with two columns: `'C'` and `'accuracy'`. The column `'C'` contains the elements of the input list `C_vals`. The column `'accuracy'` contains the corresponding accuracy score as computed in the loop just described."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def log_reg_gridsearch(X, y, C_vals):\n",
    "    '''\n",
    "    Input: predictor X values, target y values, and a list of\n",
    "    values for C in the LogisticRegression estimator.\n",
    "    \n",
    "    Output: DataFrame with accuracy scores & C values\n",
    "    '''\n",
    "    # DO NOT CHANGE THE LINE BELOW\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "    score = []\n",
    "    for c_val in C_vals:\n",
    "        pipe = Pipeline([('scaler', StandardScaler()), ('clf', LogisticRegression(C = c_val, max_iter=1000, solver='newton-cg'))])\n",
    "        pipe.fit(X_train,y_train)\n",
    "        y_pred = pipe.predict(X_test)\n",
    "        confusion_mat = confusion_matrix(y_true, y_pred)\n",
    "        score.append(accuracy_score(confusion_mat))\n",
    "        confusion_mat = None\n",
    "    return pd.DataFrame({'C': C_vals, 'accuracy': score})\n",
    "###\n",
    "### Insert your solution here:\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 10",
     "locked": true,
     "points": "15",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Decision Trees\n",
    "\n",
    "Now, we turn to a different classifier -- the `DecisionTreeClassifier`.  The aim is to compare its performance to that of our `LogisticRegression` classifier. As with `LogisticRegression` and other estimators, the specific performance and behavior of the `DecisionTreeClassifier` can be tuned by specifying certain *hyperparameters* upon instantiation. Some useful hyperparameters for the `DecisionTreeClassifier` are:\n",
    "\n",
    "* `criterion`: `'gini'` (default) for the Gini impurity or `'entropy'` for the information gain\n",
    "* `max_depth`: depth of tree (default `None`; expands until all nodes are pure)\n",
    "* `min_samples_split`: minimum number of samples required to split a node (default 2)\n",
    "\n",
    "We also would like to search over different hyperparameters relevant to this classifier as well.  In the problem below, you are asked to fit a `DecisionTreeClassifier` and search over the three hyperparameters listed above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#questions)\n",
    "\n",
    "---\n",
    "\n",
    "<a id='q11'></a>\n",
    "### Question 11: Decision Tree\n",
    "\n",
    "Your task here is to build a function `decision_tree_gridsearch` similar to that in Question 10. The function `decision_tree_gridsearch` accepts as input arguments the input feature matrix `X`, the target vector `y`, a list `criteria` of strings (either `'gini'` or `'entropy'` or both), a list `depths` of positive integers, and a list `min_splits` of positive integers.\n",
    "\n",
    "The input data is split into training & test sets with a fixed random parameter 42 (done for you).\n",
    "From there, your function will loop over all the hyperparameter values within the three input lists.\n",
    "For each hyperparameter combination, you will:\n",
    "* instantiate a `DecisionTreeClassifier` object\n",
    "* the `DecisionTreeClassifier` estimator is instantiated with hyperparameters `criterion`, `max_depth`, and `min_samples_split` determined from the input\n",
    "* the `DecisionTreeClassifier` is fit to the training data `X_train` & `y_train`\n",
    "* the `DecisionTreeClassifier` is used to predict target values from the test data `X_test`\n",
    "* the accuracy score (as computed using the estimator `score` method or the function `accuracy_score`\n",
    "  from Question 6).\n",
    "\n",
    "The result returned by the function is a DataFrame with four columns: `'criterion'`, `'max_depth'`, `'min_samples_split'`, and `'accuracy'` . The first three columns contain all combinations of the hyperparameter values from the input lists. The column `'accuracy'` contains the corresponding accuracy score as computed in the loop just described."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def decision_tree_gridsearch(X, y, criteria, max_depths, min_splits):\n",
    "    '''\n",
    "    Input: predictor X values, target y values, and lists criteria,\n",
    "           max_depths, & min_splits of hyperparameter values for\n",
    "           the DecisionTreeClassifier.\n",
    "    \n",
    "    Output: DataFrame with accuracy scores & hyperparameter values;\n",
    "            column headings as follows:\n",
    "            | 'criterion' | 'max_depth' | 'min_samples_split' | 'accuracy' |\n",
    "            ----------------------------------------------------------------\n",
    "    '''\n",
    "    # DO NOT CHANGE NEXT LINE\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    X_train_, X_test_, y_train_, y_test_ = train_test_split(X, y, random_state=42)\n",
    "    crite = maxdep = minsamp = acc = []\n",
    "    for c in criteria:\n",
    "        for d in max_depths:\n",
    "            for s in min_splits:\n",
    "                cls = DecisionTreeClassifier(criterion = c,max_depth = d,min_samples_split = s)\n",
    "                cls.fit(X_train, y_train)\n",
    "                ypred = cls.predict(X_test)\n",
    "                score = accuracy_score(y_test_,ypred)\n",
    "                crite.append(c)\n",
    "                maxdep.append(d)\n",
    "                minsamp.append(s)\n",
    "                acc.append(score)\n",
    "    \n",
    "    return pd.DataFrame({'criterion': crite, 'max_depth':maxdep,'min_samples_split': minsamp,'accuracy':acc})\n",
    "    \n",
    "###\n",
    "### Insert your solution here:\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 11",
     "locked": true,
     "points": "20",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Machine Learning on Graphs\n",
    "\n",
    "<center>\n",
    "    <img src = https://www.impacttrophies.co.uk/content/images/thumbs/0050284_male-karatetaekwondo-trophy-figure-top.jpeg width = 20% />\n",
    "    </center>\n",
    "    \n",
    "    \n",
    "In the first part of the assignment, we investigate how to apply some basic machine learning concepts to graph structures.  This involves structuring data from a graph in familiar tabular format.  We will begin by looking at a classic graph from Zachary's Karate Club.  This is built in to `networkx` and has an attribute called `club` associated with each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#create the graph \n",
    "K = nx.karate_club_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Zachary's Karate Club\n",
      "Type: Graph\n",
      "Number of nodes: 34\n",
      "Number of edges: 78\n",
      "Average degree:   4.5882\n"
     ]
    }
   ],
   "source": [
    "#print info\n",
    "print(nx.info(K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeView((0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'club': 'Mr. Hi'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking node structure\n",
    "K.nodes[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mr. Hi'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# node attributes\n",
    "K.nodes[5]['club']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mr. Hi'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the value\n",
    "K.nodes[0]['club']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this graph, we can construct a `DataFrame` object using the nodes as indicies.  Then, we will map the attributes of the nodes `'club'` values to a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "karate = pd.DataFrame(index=K.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "karate['club'] = [K.nodes[i]['club'] for i in karate.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>club</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Mr. Hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Mr. Hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Mr. Hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Mr. Hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Mr. Hi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     club\n",
       "0  Mr. Hi\n",
       "1  Mr. Hi\n",
       "2  Mr. Hi\n",
       "3  Mr. Hi\n",
       "4  Mr. Hi"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "karate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Officer    17\n",
       "Mr. Hi     17\n",
       "Name: club, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "karate.club.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#questions)\n",
    "\n",
    "---\n",
    "\n",
    "<a id='q12'></a>\n",
    "### Question 12: Adding Degree Feature\n",
    "\n",
    "After we have the club feature established, we aim to use features of the graph to translate into new features in our `DataFrame`.  To start, we can determine the degree of each vertex and incorporate these as features in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DegreeView({0: 16, 1: 9, 2: 10, 3: 6, 4: 3, 5: 4, 6: 4, 7: 4, 8: 5, 9: 2, 10: 3, 11: 1, 12: 2, 13: 5, 14: 2, 15: 2, 16: 2, 17: 2, 18: 2, 19: 3, 20: 2, 21: 2, 22: 2, 23: 5, 24: 3, 25: 3, 26: 2, 27: 4, 28: 3, 29: 4, 30: 4, 31: 6, 32: 12, 33: 17})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.degree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### QUESTION 12\n",
    "### Create a new feature named 'degree'.\n",
    "### Add this to the \"karate\" DataFrame.\n",
    "### YOUR SOLUTION HERE:\n",
    "karate['degree'] = dict(K.degree()).values()\n",
    "#If the above statement gives wrong answer try this\n",
    "#karate['degree'] = K.degree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 12",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#questions)\n",
    "\n",
    "---\n",
    "\n",
    "<a id='q13'></a>\n",
    "### Question 13: Clustering Coefficients\n",
    "\n",
    "<center>\n",
    "    <img src = \"https://upload.wikimedia.org/wikipedia/commons/thumb/5/5a/Complete_graph_K3.svg/320px-Complete_graph_K3.svg.png\" width = 20%/>\n",
    "    </center>\n",
    "    \n",
    "    \n",
    "    \n",
    "From [*Wikipedia*](https://en.wikipedia.org/wiki/Clustering_coefficient):\n",
    "\n",
    "> *\"In graph theory, a clustering coefficient is a measure of the degree to which nodes in a graph tend to cluster together. Evidence suggests that in most real-world networks, and in particular social networks, nodes tend to create tightly knit groups characterised by a relatively high density of ties; this likelihood tends to be greater than the average probability of a tie randomly established between two nodes\"*\n",
    "\n",
    "$$\n",
    "{\\displaystyle C={\\frac {3\\times {\\mbox{number of triangles}}}{\\mbox{number of all triplets}}}} $$\n",
    "\n",
    "In `networkx`, we can execute this computation using the function `nx.clustering`:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.15, 1: 0.3333333333333333, 2: 0.24444444444444444, 3: 0.6666666666666666, 4: 0.6666666666666666, 5: 0.5, 6: 0.5, 7: 1.0, 8: 0.5, 9: 0, 10: 0.6666666666666666, 11: 0, 12: 1.0, 13: 0.6, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 0.3333333333333333, 20: 1.0, 21: 1.0, 22: 1.0, 23: 0.4, 24: 0.3333333333333333, 25: 0.3333333333333333, 26: 1.0, 27: 0.16666666666666666, 28: 0.3333333333333333, 29: 0.6666666666666666, 30: 0.5, 31: 0.2, 32: 0.19696969696969696, 33: 0.11029411764705882}\n"
     ]
    }
   ],
   "source": [
    "print(nx.clustering(K))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Notice that the output of `nx.clustering` is a Python `dict` with the node labels as keys and the corresponding clustering coefficients as values. Observe also that this function iterates over the entire graph and computes all the clustering coefficients at once (this will be relevant later when you have to work with a relatively large graph)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### QUESTION 13\n",
    "### Add a feature 'cluster_coef' to the\n",
    "### karate dataframe below using the \n",
    "### nx.clustering() method.\n",
    "karate['cluster_coef'] = dict(nx.clustering(K)).values()\n",
    "#If the above statement gives wrong answer try this\n",
    "#karate['cluster_coef'] = nx.clustering(K)\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 13",
     "locked": true,
     "points": "6",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#questions)\n",
    "\n",
    "---\n",
    "\n",
    "<a id='q14'></a>\n",
    "### Question 14: Big Influencers\n",
    "\n",
    "The scenario for our karate club involves a rift in the members, and subsequent splitting into two clubs. Your task is to predict who will join which club.  Another feature that could be helpful involves the distance each node is from the two protagonists.  These individuals correspond to the two nodes of highest degree in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### QUESTION 14\n",
    "### Identify the two nodes with highest degree.\n",
    "### Save their indicies in order to sensei_1 and sensei_2 below.\n",
    "### YOUR SOLUTION HERE:\n",
    "sensei = karate['degree'].values\n",
    "res = sorted( [(x,i) for (i,x) in enumerate(sensei)], reverse=True )[:2]\n",
    "sensei_1 = res[0][1] # largest degree node index\n",
    "sensei_2 = res[1][1]  # second highest degree node index\n",
    "#print(sensei_1,sensei_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 14",
     "locked": true,
     "points": "8",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mr. Hi'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.nodes[sensei_2]['club']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#questions)\n",
    "\n",
    "---\n",
    "\n",
    "<a id='q15'></a>\n",
    "### Question 15: Adding distance features (I)\n",
    "\n",
    "We will identify the highest degree node (i.e., `sensei_1`)  as `Officer` and the second highest (i.e., `sensei_2`) as `Mr. Hi`.  Subsequently, we want to measure the distance from each as our final features.  To do so, we can use **djikstra's** shortest path algorithm with the `.djikstra_path_length()` method for each of the influencers.\n",
    "\n",
    "+ The task here is append a column `dist_officer` to the DataFrame that reveals the distance of each member to `Officer` (or `sensei_1`) in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### QUESTION 15\n",
    "### Add a feature 'dist_officer' that is the \n",
    "### length of the shortest path from each vertex\n",
    "### to the highest degree vertex.\n",
    "### YOUR SOLUTION HERE:\n",
    "#print(K.nodes)\n",
    "arr = []\n",
    "for x in K.nodes:\n",
    "    arr.append(nx.dijkstra_path_length(K,x,res[0][0]))\n",
    "#print(arr)\n",
    "karate['dist_officer'] = arr\n",
    "#print(karate['dist_officer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 15",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>club</th>\n",
       "      <th>degree</th>\n",
       "      <th>cluster_coef</th>\n",
       "      <th>dist_officer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Mr. Hi</td>\n",
       "      <td>16</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Mr. Hi</td>\n",
       "      <td>9</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Mr. Hi</td>\n",
       "      <td>10</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Mr. Hi</td>\n",
       "      <td>6</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Mr. Hi</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     club  degree  cluster_coef  dist_officer\n",
       "0  Mr. Hi      16      0.150000             1\n",
       "1  Mr. Hi       9      0.333333             1\n",
       "2  Mr. Hi      10      0.244444             2\n",
       "3  Mr. Hi       6      0.666667             2\n",
       "4  Mr. Hi       3      0.666667             2"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "karate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#questions)\n",
    "\n",
    "---\n",
    "\n",
    "<a id='q16'></a>\n",
    "## Question 16: Adding distance features (II)\n",
    "\n",
    "Your task here is to repeat the computation from the preceding question by computing the shortest path distance (as measured by number of edges) from each member to `Mr. Hi` (i.e., `sensei_2`, the node of second highest degree).\n",
    "+ Label this new column `dist_mrhi`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### QUESTION 16\n",
    "### Add a feature 'dist_mrh' that is the \n",
    "### length of the shortest path from each vertex\n",
    "### to the second highest degree vertex.\n",
    "### YOUR SOLUTION HERE:\n",
    "arr = []\n",
    "for x in K.nodes:\n",
    "    arr.append(nx.dijkstra_path_length(K,x,res[1][0]))\n",
    "karate['dist_mrh'] = arr\n",
    "#print(karate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "Question  16",
     "locked": true,
     "points": "8",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>club</th>\n",
       "      <th>degree</th>\n",
       "      <th>cluster_coef</th>\n",
       "      <th>dist_officer</th>\n",
       "      <th>dist_mrh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Mr. Hi</td>\n",
       "      <td>16</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Mr. Hi</td>\n",
       "      <td>9</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Mr. Hi</td>\n",
       "      <td>10</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Mr. Hi</td>\n",
       "      <td>6</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Mr. Hi</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     club  degree  cluster_coef  dist_officer  dist_mrh\n",
       "0  Mr. Hi      16      0.150000             1         2\n",
       "1  Mr. Hi       9      0.333333             1         3\n",
       "2  Mr. Hi      10      0.244444             2         3\n",
       "3  Mr. Hi       6      0.666667             2         3\n",
       "4  Mr. Hi       3      0.666667             2         2"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "karate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#questions)\n",
    "\n",
    "---\n",
    "\n",
    "<a id='q17'></a>\n",
    "### Question 17: `LogisticRegression`\n",
    "\n",
    "After building our features, we can see if we are in fact able to predict the `club` feature using a `LogisticRegression` classifier.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "X = karate.drop('club', axis = 1)\n",
    "y = karate.club\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 124)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.71428571, 0.71428571, 0.83333333, 1.        ])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf, X_train, y_train, cv = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### QUESTION 17\n",
    "### Use cross-validation as above but add arguments\n",
    "### to group data based on y and to use 5 folds.\n",
    "### Save your results to ans17 below.\n",
    "### YOUR SOLUTION HERE:\n",
    "ans17 = cross_val_score(clf, X_train, y_train, cv = 5) # array of cross_val roc_auc scores\n",
    "#print(ans17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 17",
     "locked": true,
     "points": "3",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#questions)\n",
    "\n",
    "In our Karate Club example, we were dealing with a very small community sample.  Now, we move to investigate an email network containing information about salary and department.  Here, we have a larger dataset as well as one additional attribute for each node that we can incorporate into our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/email_prediction.gpickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-f0c7160efe80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_gpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/email_prediction.gpickle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m</opt/anaconda3/lib/python3.7/site-packages/decorator.py:decorator-gen-713>\u001b[0m in \u001b[0;36mread_gpickle\u001b[0;34m(path)\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/networkx/utils/decorators.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(func_to_be_decorated, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             \u001b[0mfobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dispatch_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m             \u001b[0mclose_fobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'read'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/email_prediction.gpickle'"
     ]
    }
   ],
   "source": [
    "G = nx.read_gpickle('data/email_prediction.gpickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_gpickle('email_prediction.gpickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nx.info(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.nodes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#questions)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "<a id='q18'></a>\n",
    "### QUESTION 18: A Larger Example\n",
    "\n",
    "Your task here is to construct a `DataFrame` object from the graph `G` loaded above.\n",
    "+ The columns should be `dept`, `management_salary`, `cluster`, and `degree`.\n",
    "+ The `dept` and `management_salary` features can be extracted from the attributes of the nodes.\n",
    "+ The `degree` and `cluster` attributes can be computed using `networkx` functions.\n",
    "+ *Warning*: for a graph of this size, redundant graph computations can lead to time-outs. Be careful to structure your computation to avoid repeated computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### QUESTION 18\n",
    "### Create a DataFrame \"salaries\"\n",
    "### as above indexed by nodes\n",
    "### containing features named \n",
    "### 'dept', 'management_salary',\n",
    "### 'cluster', 'degree'.\n",
    "dept=[]\n",
    "salary=[]\n",
    "for k,v in G.nodes(data=True):\n",
    "    dept.append(v['Department'])\n",
    "    salary.append(v['ManagementSalary'])\n",
    "salaries = pd.DataFrame()\n",
    "salaries['dept'] = dept\n",
    "salaries['management_salary'] = salary\n",
    "salaries['cluster'] = dict(nx.clustering(G)).values()\n",
    "salaries['degree'] = dict(G.degree()).values()\n",
    "#print(salaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 18",
     "locked": true,
     "points": "8",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#questions)\n",
    "\n",
    "---\n",
    "\n",
    "<a id='q19'></a>\n",
    "### Question 19: Structuring the Data\n",
    "\n",
    "Your goal is to predict salaries for the nodes missing data.  We proceed by splitting the data into two sets; `labeled` and `not_labeled`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "Question 19",
     "locked": false,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### QUESTION 19\n",
    "### Using the DataFrame loaded below, create\n",
    "### two subsets of the frame determined by if \n",
    "### the management_salary in NaN or not.\n",
    "salaries = pd.read_csv('data/salary_clean.csv', index_col = 0)\n",
    "#salaries = pd.read_csv('salary_clean.csv', index_col = 0)\n",
    "### YOUR SOLUTION HERE:\n",
    "labeled = salaries[salaries['management_salary'].notnull()] # DataFrame of observations with management_salary data\n",
    "not_labeled = salaries[salaries['management_salary'].isnull()] # DataFrame of observations missing labels in management_salary\n",
    "#print(labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 19",
     "locked": true,
     "points": "6",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#questions)\n",
    "\n",
    "---\n",
    "\n",
    "<a id='q20'></a>\n",
    "### Question 20: Training a Classifier\n",
    "\n",
    "Now, you can build a basic `LogisticRegression` model on our data. Note that you build a split on the labeled data only, and reserve the unlabeled data for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(labeled.drop('management_salary', axis = 1),\n",
    "                                                    labeled['management_salary'], random_state = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### QUESTION 20\n",
    "### Create a basic LogisticRegression classifier.\n",
    "### This estimator should achieve an roc_auc score better than 0.6\n",
    "lgr = LogisticRegression()\n",
    "score = cross_val_score(lgr, X_train, y_train, scoring = 'roc_auc').mean()\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n",
    "print(\"Your roc_auc_score is : {:8.6f}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 20",
     "locked": true,
     "points": "6",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#questions)\n",
    "\n",
    "---\n",
    "\n",
    "<a id='q21'></a>\n",
    "### Question 21: Bagging Classifiers\n",
    "\n",
    "From the documentation:\n",
    "\n",
    "```\n",
    "A Bagging classifier is an ensemble meta-estimator that fits base\n",
    "classifiers each on random subsets of the original dataset and then\n",
    "aggregate their individual predictions (either by voting or by averaging)\n",
    "to form a final prediction. Such a meta-estimator can typically be used as\n",
    "a way to reduce the variance of a black-box estimator (e.g., a decision\n",
    "tree), by introducing randomization into its construction procedure and\n",
    "then making an ensemble out of it.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# base estimator\n",
    "lgr = LogisticRegression()\n",
    "# bagging classifier\n",
    "bag = BaggingClassifier(lgr, random_state = 24)\n",
    "# fit \n",
    "scores = cross_val_score(bag, X_train, y_train, scoring = 'roc_auc')\n",
    "# score\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### QUESTION 21\n",
    "### Fit the data with a bagged KNearestNeighbor estimator\n",
    "### and save your cross-validated roc_auc score average to bag_knn below.\n",
    "### YOUR SOLUTION HERE:\n",
    "bag = BaggingClassifier(knn, random_state = 24)\n",
    "bag_knn = cross_val_score(bag, X_train, y_train, scoring = 'roc_auc').mean()\n",
    "print('Your roc_auc_score is : {:8.6f}'.format(bag_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 21",
     "locked": true,
     "points": "6",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#questions)\n",
    "\n",
    "---\n",
    "\n",
    "<a id='q22'></a>\n",
    "### Question 22: Boosting Classifiers\n",
    "\n",
    "```\n",
    "An AdaBoost classifier is a meta-estimator that begins by fitting a\n",
    "classifier on the original dataset and then fits additional copies of the\n",
    "classifier on the same dataset but where the weights of incorrectly\n",
    "classified instances are adjusted such that subsequent classifiers focus\n",
    "more on difficult cases.\n",
    "```\n",
    "\n",
    "By default, the classifier is a `DecisionTreeClassifier`.  Below is an example from the [user guide](https://scikit-learn.org/stable/modules/ensemble.html#adaboost).  We will use the `AdaBoostClassifier` and the `GradientBoostingClassifier` here.  These boostings adjust themselves in different manners; AdaBoost focuses on misclassified data each iteration and the GradientBoost focuses on the gradient of a loss function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "clf = AdaBoostClassifier(n_estimators=100, random_state=24)\n",
    "scores = cross_val_score(clf, X_train, y_train, cv = 5, scoring = 'roc_auc')\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "    max_depth=1, random_state=24)\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5, scoring = 'roc_auc')\n",
    "scores.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "### QUESTION 22\n",
    "### Above, we compare the AdaBoostClassifier and GradientBosstingClassifier's\n",
    "### performance on our data through cross-validation.  Which classifier performed\n",
    "### better according to cross validation on the training data? Assign your answer to ans22 below.\n",
    "### a) AdaBoost\n",
    "### b) GradientBoost\n",
    "### c) Neither\n",
    "### YOUR SOLUTION HERE:\n",
    "ans22 = 'b'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "Question 22",
     "locked": true,
     "points": "3",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#questions)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
